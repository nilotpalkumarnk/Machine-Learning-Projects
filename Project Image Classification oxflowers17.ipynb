{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project Image Classification oxflowers17.ipynb","private_outputs":true,"provenance":[{"file_id":"1mpOXuzqjcC_5LGIVQUzwZ-fK7MLyRFA5","timestamp":1622736622821}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"x182yUaaGOIx"},"source":["### Download Flowers dataset"]},{"cell_type":"code","metadata":{"id":"USgEKN9GGf60"},"source":["#You can download the data manually as well instead of using 'wget'\n","!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cCPVwdxpDvR"},"source":["#Check if file is downloaded\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9NeLYrOpIc0"},"source":["#Unzip the data\n","!tar -xf 17flowers.tgz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fd2Zz_mYrU7N"},"source":["#Check how data is organized\n","!ls -l 17flowers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lz0v83zDhs2y"},"source":["### Build batch generator"]},{"cell_type":"code","metadata":{"id":"-da8Sz_BpnpI"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQQ7Oksaq7tI"},"source":["#Define some parameters\n","img_size = 60\n","img_depth = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FBkyCTo1qWMy"},"source":["Create an ImageDataGenerator object, it can also split data between train and test."]},{"cell_type":"code","metadata":{"id":"bkUsCc6zp7Kp"},"source":["#ImageDataGenerator declaration with 20% data as test (80% for training)\n","img_generator= tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q3BVmtXdrHyh"},"source":["ImageDataGenerator can read images directory and also resize them if needed"]},{"cell_type":"code","metadata":{"id":"IkCVDrPOqDjE"},"source":["#Build training generator. \n","train_generator = img_generator.flow_from_directory('flower_photos',\n","                                                    target_size=(img_size, img_size),\n","                                                    subset='training',\n","                                                    batch_size=64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Z7_0KoJGRDM"},"source":["#Build test generator\n","test_generator = img_generator.flow_from_directory('flower_photos',\n","                                                   target_size=(img_size, img_size),                                                   \n","                                                   subset='validation',\n","                                                   batch_size=64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZnOY195Pt7mn"},"source":["type(train_generator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dCpXm9s4rjM1"},"source":["ImageDataGenerator returns 64 images and their labels"]},{"cell_type":"code","metadata":{"id":"aUhNi9Krrpq7"},"source":["#Lets check the features (images) and Labels (flower class) returned by ImageDataGenerator\n","X, y = next(train_generator)\n","\n","print('Input features shape', X.shape)\n","print('Actual labels shape', y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NUb1CcQx_Zo"},"source":["y[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iJgvxvh32gt"},"source":["import numpy as np\n","np.unique(X[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"es0UPokXxIKM"},"source":["train_generator.class_indices"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDV8kVGpOi_w"},"source":["X[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p1DOwu8Bhs29"},"source":["### Build CNN Model"]},{"cell_type":"code","metadata":{"id":"tWQJ4SzZhs2-"},"source":["#Clear any previous model from memory\n","tf.keras.backend.clear_session()\n","\n","#Initialize model\n","model = tf.keras.models.Sequential()\n","\n","#normalize data\n","model.add(tf.keras.layers.BatchNormalization(input_shape=(img_size,img_size,3,)))\n","\n","#Add Conv Layer\n","model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n","\n","#normalize data\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","#Add Conv Layer\n","model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n","\n","#normalize data\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","#Add Max Pool layer\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","#Add Dense Layers after flattening the data\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(128, activation='relu'))\n","\n","#Add Dropout\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","#Add Output Layer\n","model.add(tf.keras.layers.Dense(5, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsuEXbofhs3D"},"source":["#Specify Loass and Optimizer\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0V1E9Ua1tUPP"},"source":["#Model Summary\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0v7UlgC5hs3g"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"cklB73X8yCvt"},"source":["model_checkpoint = tf.keras.callbacks.ModelCheckpoint('flowers.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldJt7GHB5dtQ"},"source":["2939//64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YGqTxKQhs3l"},"source":["model.fit(train_generator,\n","          epochs=200,\n","          steps_per_epoch= 2939//64,  #Number of batches per epoch\n","          validation_data=test_generator,\n","          validation_steps = 731//64, \n","          callbacks=[model_checkpoint]) #Number of test images//batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3iNMg3lr6EI"},"source":[""],"execution_count":null,"outputs":[]}]}