{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport matplotlib.pyplot as plt # data visualization library\n%matplotlib inline\nimport seaborn as sns\n\nimport re\nimport nltk\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score\n\n\nfrom nltk.tokenize import word_tokenize\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer #word stemmer class\nlemma = WordNetLemmatizer()\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk import FreqDist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Load the dataset "},{"metadata":{"trusted":false},"cell_type":"code","source":"#select 5000 rows\ndf = pd.read_csv('/kaggle/input/vehicle/vehicle.csv', nrows= 5000)\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Preprocess rows of the “text” column \n#### a. Remove unwanted characters\n#### b. Convert text to lowercase\n#### c. Remove unwanted spaces\n#### d. Remove stopwords"},{"metadata":{"trusted":false},"cell_type":"code","source":"words = set(nltk.corpus.words.words())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def normalizer(blogs):\n    blogs = \" \".join(filter(lambda x: x[0]!= '@' , blogs.split()))\n    blogs = re.sub('[^a-zA-Z]', ' ', blogs)\n    blogs = blogs.lower()\n    blogs = re.sub(' +', ' ', blogs).strip()\n    blogs = blogs.split()\n    blogs = [word for word in blogs if not word in set(stopwords.words('english'))]\n    blogs = [lemma.lemmatize(word) for word in blogs]\n    \n    blogs = \" \".join(blogs)\n    return blogs","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df['normalized_text'] = df.text.apply(normalizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove Non-English Words from Normalized text\ndef remove_non_english_words(blog):\n    return \" \".join(w for w in nltk.wordpunct_tokenize(blog) if w.lower() in words or not w.isalpha())\n\ndf['normalized_text'] = df.normalized_text.apply(remove_non_english_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Word Cloud of all the normlized text"},{"metadata":{"trusted":false},"cell_type":"code","source":"# all tweets \nall_words = \" \".join(df.normalized_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"wordcloud = WordCloud(height=2000, width=2000, stopwords=STOPWORDS, background_color='white')\nwordcloud = wordcloud.generate(all_words)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. As we want to make this into a multi-label classification problem, you are required to merge all the label columns together, so that we have all the labels together for a particular sentence (7.5 points)"},{"metadata":{},"cell_type":"markdown","source":"#### a. Label columns to merge: “gender”, “age”, “topic”, “sign”"},{"metadata":{"trusted":false},"cell_type":"code","source":"##  create another dataframe dfT having only the columns needed for creating label\ndfT=df[['gender', 'age', 'topic', 'sign']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## Convert age from int type into String\ndfT['age']=dfT['age'].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## Create a 2D Matrix 'm' which is list of list contaning 'gender', 'age', 'topic', 'sign' for each row\nm=[]                              # 2D Matrix having list of list\nfor i in range(dfT.shape[0]):\n    g=[]                          # 1D list of 'gender', 'age', 'topic', 'sign'\n    for j in range(dfT.shape[1]):\n        g.append(dfT.iloc[i][j])\n    m.append(g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Add a column called labels\ndf['labels']=m","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### b. After completing the previous step, there should be only two columns in your data frame i.e. “text” and “labels” as shown in the below image"},{"metadata":{"trusted":false},"cell_type":"code","source":"final_df = df[['normalized_text', 'labels']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Lets Check Distribution of Labels\nfinal_df['labels'].astype('str').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## Check for Null Values\nfinal_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# No Null Values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Separate features and labels, and split the data into training and testing "},{"metadata":{"trusted":false},"cell_type":"code","source":"X = final_df['normalized_text']\ny = final_df['labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Vectorize the features \n#### a. Create a Bag of Words using count vectorizer\n#### i. Use ngram_range=(1, 2)\n##### ii. Vectorize training and testing features\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Consider only those rows which occur more than 15% and less than 80 %, also restrict features to 100\n\nvectorizer = CountVectorizer(ngram_range = (1,2), stop_words=stopwords.words('english'), \n                             min_df = 0.15, max_df = 0.8, max_features = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# transform the X data to document_term_matrix\n\nX_train_dtm = vectorizer.fit_transform(X_train)\nX_test_dtm = vectorizer.transform(X_test)\nX_train_dtm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# check the vocabulary( First 15 features)\nvectorizer.get_feature_names()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### b. Print the term-document matrix"},{"metadata":{},"cell_type":"markdown","source":"##### Train Document Term Matrix"},{"metadata":{"trusted":false},"cell_type":"code","source":"\nprint(X_train_dtm )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# examine vocabulary and document term matrix together\npd.DataFrame(X_train_dtm.toarray(), columns = vectorizer.get_feature_names())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Test Document Term Matrix"},{"metadata":{"trusted":false},"cell_type":"code","source":"\nprint(X_train_dtm )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# examine vocabulary and document term matrix together\npd.DataFrame(X_test_dtm.toarray(), columns = vectorizer.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a dictionary to get the count of every label i.e. the key will be label name and value will be the total count of the label. Check below image for reference (5 points)"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfT = df[['gender', 'age', 'topic', 'sign']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfT['age'] = dfT['age'].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"keys=[] \nvalues=[] \n\nfor i in range(dfT.shape[1]): # iterate through all the colummns        \n    for j in range(dfT.iloc[:,i].value_counts().shape[0]): # iterate through all the rows of value_counts of that column\n        keys.append(dfT.iloc[:,i].value_counts().index[j])         \n        values.append(dfT.iloc[:,i].value_counts().iloc[j])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dictionary = dict(zip(keys,values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(dictionary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Transform the labels - (7.5 points)\nAs we have noticed before, in this task each example can have multiple tags. To deal with\nsuch kind of prediction, we need to transform labels in a binary form and the prediction will be\na mask of 0s and 1s. For this purpose, it is convenient to use MultiLabelBinarizer from sklearn\n\n#### a. Convert your train and test labels using MultiLabelBinarizer"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer \nmlb = MultiLabelBinarizer(classes=sorted(dictionary.keys()))\ny_train_mlb = mlb.fit_transform(y_train)\ny_test_mlb = mlb.transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_mlb[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_test_mlb[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Lets verify one single row of train set after MLB conversion"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train.iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mlb.inverse_transform(y_train_mlb)[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Result as expected"},{"metadata":{},"cell_type":"markdown","source":"# 8. Choose a classifier \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver='lbfgs', multi_class='ovr')\novr = OneVsRestClassifier(lr)\n\novr.fit(X_train_dtm, y_train_mlb)\ny_pred_ovr_test = ovr.predict(X_test_dtm)\n#y_proba_ovr = ovr.predict_proba(X_test_dtm)\ny_pred_ovr_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_ovr_train = ovr.predict(X_train_dtm)\ny_pred_ovr_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Fit the classifier, make predictions and get the accuracy \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"def print_scores(actual, predicted, averaging_type):\n    print('\\nAVERAGING TYPE==> ',averaging_type)\n    print('F1 score: ',f1_score(actual,predicted, average=averaging_type))\n    print('Average Precision Score: ',average_precision_score(actual,predicted, average=averaging_type))\n    print('Average Recall Score: ',recall_score(actual,predicted, average=averaging_type))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Train Score"},{"metadata":{"trusted":false},"cell_type":"code","source":"print('--------------------------TRAIN SCORES--------------------------------')\nprint('Accuracy score: ',accuracy_score(y_train_mlb, y_pred_ovr_train))\nprint_scores(y_train_mlb, y_pred_ovr_train, 'micro')\nprint_scores(y_train_mlb, y_pred_ovr_train, 'macro')\nprint_scores(y_train_mlb, y_pred_ovr_train, 'weighted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Test Scores"},{"metadata":{"trusted":false},"cell_type":"code","source":"print('--------------------------TEST SCORES--------------------------------')\nprint('Accuracy score: ',accuracy_score(y_test_mlb, y_pred_ovr_test))\nprint_scores(y_test_mlb, y_pred_ovr_test, 'micro')\nprint_scores(y_test_mlb, y_pred_ovr_test, 'macro')\nprint_scores(y_test_mlb, y_pred_ovr_test, 'weighted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Print true label and predicted label for any five examples"},{"metadata":{"trusted":false},"cell_type":"code","source":"five_pred = y_pred_ovr_test[:5]\nfive_actual = y_test_mlb[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"five_actual = mlb.inverse_transform(five_actual)\nfive_actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"five_pred = mlb.inverse_transform(five_pred)\nfive_pred","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}