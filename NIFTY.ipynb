{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIFTY.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fi2mGQVyDC8-"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a2b71cb350d42e088dfcf2de8cb20f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8761ba48cf1144adbdf251e85e22d006",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc9851dbceed413388b38cbf3f7c8f64"
          }
        },
        "8761ba48cf1144adbdf251e85e22d006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc9851dbceed413388b38cbf3f7c8f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a7970fd23754af2ae8992a0515b4c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7557a40ab83940569355ea2d27c74b31",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 94,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 94,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f872aa58984408aabecab633fdade11"
          }
        },
        "7557a40ab83940569355ea2d27c74b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f872aa58984408aabecab633fdade11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b2429c1e040476e83a20dd5fc9f29a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_732229ce5f8a4a749c44709db4c1856f",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 6,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_930dc68524d74f49b57ec4ae5e1d3ba5"
          }
        },
        "732229ce5f8a4a749c44709db4c1856f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "930dc68524d74f49b57ec4ae5e1d3ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma02wxbN0oiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbe1323-1547-496d-e26a-3954cb7b82e2"
      },
      "source": [
        "#!pip install catboost\n",
        "!pip install -U scikit-learn\n",
        "#!pip install sklego\n",
        "!pip install pycaret-nightly\n",
        "from pycaret.utils import enable_colab \n",
        "!pip install pyts\n",
        "!pip install sktime\n",
        "!pip install tsmoothie\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/4c/6111b9a325f29527d7f262e2ee8c730d354b47a728d955e186dacad57a0d/scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n",
            "Collecting pycaret-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ae/aedc5ba4d3a4bffa7628e60463b7d63f6eb5ca42254d2bf7691fbc2a333b/pycaret_nightly-2.2.3.dev1611880622-py3-none-any.whl (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (5.5.0)\n",
            "Collecting xgboost>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/57/bf5026701c384decd2b995eb39d86587a103ba4eb26f8a9b1811db0896d3/xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5MB)\n",
            "\u001b[K     |████████████████████████████████| 157.5MB 55kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (1.19.5)\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/55/d8ec1ae1f7e1e202a8a4184c6852a3ee993b202b0459672c699d0ac18fc8/kmodes-0.10.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (3.2.5)\n",
            "Collecting catboost>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/37/bc4e0ddc30c07a96482abf1de7ed1ca54e59bba2026a33bca6d2ef286e5b/catboost-0.24.4-cp36-none-manylinux1_x86_64.whl (65.7MB)\n",
            "\u001b[K     |████████████████████████████████| 65.8MB 77kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (2.2.4)\n",
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (0.5.0)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (1.4.1)\n",
            "Collecting imbalanced-learn>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl (167kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 62.2MB/s \n",
            "\u001b[?25hCollecting yellowbrick>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/bb/57fd86c319a43666fe447bb1bc5af66fb0eb89dc4efc305a7544d50f52d6/yellowbrick-1.2.1-py3-none-any.whl (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 55.3MB/s \n",
            "\u001b[?25hCollecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (3.2.2)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (0.14.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (3.6.0)\n",
            "Collecting scikit-learn==0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 51.9MB/s \n",
            "\u001b[?25hCollecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/26/ae4f4143643d2d87fe4bbc356064dd95eed95227b879ba3ee6c4e4ee81ca/pyod-0.8.6.tar.gz (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (1.0.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (0.11.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (7.6.3)\n",
            "Collecting pandas-profiling>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/8e/645ad7f304dd8d6d7181d22d4bd3d6356331c80c2944a25be3ebe617ec38/pandas_profiling-2.10.0-py2.py3-none-any.whl (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (1.5.0)\n",
            "Collecting lightgbm>=2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/cd/2b7783e8c250f8191b72e9a0010e0429a799d3305c27764d7bf113dfd078/lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (0.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (1.1.5)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret-nightly) (0.15.3)\n",
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/4d/a6a4460e214842377dbc43d3e83bf976d564f7976822a9351adde60af44b/mlflow-1.13.1-py3-none-any.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (53.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret-nightly) (0.7.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->pycaret-nightly) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret-nightly) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret-nightly) (1.1.3)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret-nightly) (0.36.2)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret-nightly) (2.11.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret-nightly) (2.7.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret-nightly) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret-nightly) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.6/dist-packages (from umap-learn->pycaret-nightly) (0.51.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.6/dist-packages (from umap-learn->pycaret-nightly) (0.5.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from yellowbrick>=1.0.1->pycaret-nightly) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret-nightly) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret-nightly) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret-nightly) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret-nightly) (2.8.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret-nightly) (4.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->pycaret-nightly) (2.1.0)\n",
            "Collecting combo\n",
            "  Downloading https://files.pythonhosted.org/packages/12/ae/66029dcaa88ccca77f454dbb29c1178c751ec24fc771ed475a992b49a02d/combo-0.1.2.tar.gz\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret-nightly) (0.10.2)\n",
            "Collecting suod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/8a/255ed2c959abab7c712b10fe710e454d5a8e3461c6ae60e426349a8eb6a5/suod-0.0.6.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 56.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret-nightly) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret-nightly) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret-nightly) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret-nightly) (5.1.2)\n",
            "Collecting visions[type_image_path]==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/30/b1e70bc55962239c4c3c9660e892be2d8247a882135a3035c10ff7f02cde/visions-0.6.0-py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret-nightly) (20.3.0)\n",
            "Collecting tangled-up-in-unicode>=0.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/e2/e588ab9298d4989ce7fdb2b97d18aac878d99dbdc379a4476a09d9271b68/tangled_up_in_unicode-0.0.6-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 67.0MB/s \n",
            "\u001b[?25hCollecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/27/d4197ed93c26d9eeedb7c73c0f24462a65c617807c3140e012950c35ccf9/phik-0.11.0.tar.gz (594kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 50.6MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/55/b4726d81e5d6509fa3441f770f8a9524612627dc1b2a7d6209d1d20083fe/confuse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret-nightly) (0.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret-nightly) (7.0.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret-nightly) (0.3.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret-nightly) (2018.9)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (7.1.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/88/ae1f78cf582b707c605c77df49b4c8786a4465edc51adb25d2f98ef4c4de/databricks-cli-0.14.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (0.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (1.3.23)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (3.12.4)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (0.4.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (1.3.0)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
            "Collecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/cb/ec98155c501b68dcb11314c7992cd3df6dce193fd763084338a117967d53/GitPython-3.1.12-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 52.5MB/s \n",
            "\u001b[?25hCollecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/a5/eec74d8d1016e6c2042ba31ca6fba3bba520e27d8a061e82bccd36bd64ef/docker-4.4.1-py2.py3-none-any.whl (146kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 54.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret-nightly) (3.13)\n",
            "Collecting azure-storage-blob>=12.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/00/6772472a99cd0a5e74e4e90f87947fa041b37981a3ff93d883cbc450518d/azure_storage_blob-12.7.1-py2.py3-none-any.whl (339kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 55.3MB/s \n",
            "\u001b[?25hCollecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->pycaret-nightly) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret-nightly) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret-nightly) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret-nightly) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret-nightly) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret-nightly) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis->pycaret-nightly) (1.1.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret-nightly) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret-nightly) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret-nightly) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret-nightly) (8.6.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.49->umap-learn->pycaret-nightly) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->pyod->pycaret-nightly) (0.5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from suod->pyod->pycaret-nightly) (5.4.8)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret-nightly) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret-nightly) (5.3.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (5.3.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret-nightly) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret-nightly) (4.7.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.6.0->pandas-profiling>=2.8.0->pycaret-nightly) (2.5)\n",
            "Collecting imagehash; extra == \"type_image_path\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/9dbb772b5ef73a3069c66bb5bf29b9fb4dd57af0d5790c781c3f559bcca6/ImageHash-4.2.0-py2.py3-none-any.whl (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 61.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret-nightly) (0.8.7)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow->pycaret-nightly) (0.9.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 64.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret-nightly) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret-nightly) (1.0.1)\n",
            "Collecting azure-core<2.0.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/9e/6bb67fe85f6a89d71f50c86a0da778a5064f749a485ed9ba498067034227/azure_core-1.10.0-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 66.3MB/s \n",
            "\u001b[?25hCollecting msrest>=0.6.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cc/6c96bfb3d3cf4c3bdedfa6b46503223f4c2a4fa388377697e0f8082a4fed/msrest-0.6.21-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.5MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 47.7MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/db/2d2d88b924aa4674a080aae83b59ea19d593250bfe5ed789947c21736785/Mako-1.1.4.tar.gz (479kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 66.4MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret-nightly) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret-nightly) (22.0.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (0.9.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.6.0->pandas-profiling>=2.8.0->pycaret-nightly) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow->pycaret-nightly) (1.3.0)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow->pycaret-nightly) (1.14.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (0.8.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow->pycaret-nightly) (3.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow->pycaret-nightly) (2.20)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret-nightly) (20.9)\n",
            "Building wheels for collected packages: pyLDAvis, pyod, combo, suod, htmlmin, phik, databricks-cli, prometheus-flask-exporter, alembic, Mako\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=1d8950e6887cfed31829b5878148c422b8823faffcb5871124873f3339f64d30\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.6-cp36-none-any.whl size=112146 sha256=339a1c41aeff0be688b30875441d2554f21b58a07da83e16d84ff233497e7733\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/95/81/2c6f52c3d366e7b5ef4770550f8bf0764257c66fbe64deecdb\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.2-cp36-none-any.whl size=42028 sha256=e96d200a92b70b09698905d69447e93b1b79810e3648c88e185c16d402538e07\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/d9/bf/d1a371a5f0844cd8a53c04c14daa89974c93f429dda9dceb86\n",
            "  Building wheel for suod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suod: filename=suod-0.0.6-cp36-none-any.whl size=2154759 sha256=e552b8f13af112f64464ce1f73e1fdc89a39d390dd75df3317ef7aea68862a7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/d7/c1/6c778aee7fccfe3c054ea9bab92c5994ae3a0f6bba7078541e\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=fc1e833111f6af632f91b39b7bd6d8072b8cf293c1774309f2b295ddf6b8264f\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for phik (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phik: filename=phik-0.11.0-cp36-none-any.whl size=599738 sha256=1b76813a07ba43dd81fe51bac271a8b55e8cdaf59393563083ab4fc43ff8b4a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/54/11/aba77f21075918de02f7964eabfe8c10d5542df9e6ad10b225\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.1-cp36-none-any.whl size=100579 sha256=9efc69e272beeb42ed1759633c533577a854fce29ddca6d813ec7eeb6b7f70c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/91/ac/5d417ee5ccbb76c8cca096cf4cfb9ed9d49d889d1d1ca0fc39\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp36-none-any.whl size=17159 sha256=c7e5433b59eac607f0838e069165edcf07877c66989e45c140f85f394b080ae8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=9666f90df966db3f6c09c17a8f00097b9bd452fc3263171d0e937687781e0dd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Mako: filename=Mako-1.1.4-py2.py3-none-any.whl size=75675 sha256=f65d8753d8bde8f214cef05d7ad81e494a6648af600b2e0cda83d7bdf99784d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/10/d3/aeb26e20d19045e2a68e5d3cbb57432e11b5d9c92c99f98d47\n",
            "Successfully built pyLDAvis pyod combo suod htmlmin phik databricks-cli prometheus-flask-exporter alembic Mako\n",
            "\u001b[31mERROR: pandas-profiling 2.10.0 has requirement requests>=2.24.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas-profiling 2.10.0 has requirement tqdm>=4.48.2, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: xgboost, scikit-learn, kmodes, catboost, funcy, pyLDAvis, imbalanced-learn, yellowbrick, scikit-plot, combo, suod, pyod, tangled-up-in-unicode, imagehash, visions, htmlmin, phik, confuse, pandas-profiling, lightgbm, databricks-cli, querystring-parser, prometheus-flask-exporter, gunicorn, smmap, gitdb, gitpython, websocket-client, docker, azure-core, isodate, msrest, cryptography, azure-storage-blob, Mako, python-editor, alembic, mlflow, pycaret-nightly\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Found existing installation: scikit-learn 0.24.1\n",
            "    Uninstalling scikit-learn-0.24.1:\n",
            "      Successfully uninstalled scikit-learn-0.24.1\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "  Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed Mako-1.1.4 alembic-1.4.1 azure-core-1.10.0 azure-storage-blob-12.7.1 catboost-0.24.4 combo-0.1.2 confuse-1.4.0 cryptography-3.3.1 databricks-cli-0.14.1 docker-4.4.1 funcy-1.15 gitdb-4.0.5 gitpython-3.1.12 gunicorn-20.0.4 htmlmin-0.1.12 imagehash-4.2.0 imbalanced-learn-0.7.0 isodate-0.6.0 kmodes-0.10.2 lightgbm-3.1.1 mlflow-1.13.1 msrest-0.6.21 pandas-profiling-2.10.0 phik-0.11.0 prometheus-flask-exporter-0.18.1 pyLDAvis-2.1.2 pycaret-nightly-2.2.3.dev1611880622 pyod-0.8.6 python-editor-1.0.4 querystring-parser-1.2.4 scikit-learn-0.23.2 scikit-plot-0.3.7 smmap-3.0.5 suod-0.0.6 tangled-up-in-unicode-0.0.6 visions-0.6.0 websocket-client-0.57.0 xgboost-1.3.3 yellowbrick-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtNlwxbCJsCL",
        "outputId": "d061bf5f-618a-4cd2-998f-362bd24efce5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/2b/1a62c0d32b40ee85daa8f6a6160828537b3d846c9fe93253b38846c6ec1f/pyts-0.11.0-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.6/dist-packages (from pyts) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from pyts) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from pyts) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.6/dist-packages (from pyts) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.6/dist-packages (from pyts) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.48.0->pyts) (53.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.48.0->pyts) (0.34.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->pyts) (2.1.0)\n",
            "Installing collected packages: pyts\n",
            "Successfully installed pyts-0.11.0\n",
            "Collecting sktime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d2/cd05b0ec4cb060d0dbbd428c7949de680b7d080c768b1e758328530bfb77/sktime-0.5.2-cp36-cp36m-manylinux2014_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (0.23.2)\n",
            "Requirement already satisfied: numba>=0.50 in /usr/local/lib/python3.6/dist-packages (from sktime) (0.51.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (1.1.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from sktime) (0.36.2)\n",
            "Collecting statsmodels>=0.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/7b/c17815648dc31396af865b9c6627cc3f95705954e30f61106795361c39ee/statsmodels-0.12.2-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.0->sktime) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.0->sktime) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.0->sktime) (1.4.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.50->sktime) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.50->sktime) (53.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->sktime) (2.8.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->sktime) (1.15.0)\n",
            "Installing collected packages: statsmodels, sktime\n",
            "  Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed sktime-0.5.2 statsmodels-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AhQ-_ZmCJiJ"
      },
      "source": [
        "# load libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unS7Oir9S5jJ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sktime.classification.compose *\n",
        "from sktime.classification.dictionary_based import BOSSEnsemble\n",
        "#from sktime.classification.shapelet_based import MrSEQLClassifier\n",
        "from sktime.datasets import *\n",
        "from sktime.transformations.panel.compose import ColumnConcatenator\n",
        "#from sktime.classification.shapelet_based import MrSEQLClassifier\n",
        "from sktime.transformations.panel.rocket import *\n",
        "from pyts.classification import * \n",
        "from sktime.classification.shapelet_based import *\n",
        "from sktime.utils.slope_and_trend import _slope\n",
        "from sktime.transformations.panel.summarize import RandomIntervalFeatureExtractor\n",
        "from sktime.classification.interval_based import RandomIntervalSpectralForest\n",
        "from sktime.classification.dictionary_based._boss import *\n",
        "from sktime.classification.dictionary_based import *\n",
        "\n",
        "from tsmoothie.smoother import LowessSmoother\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXlR5ZKIyZRa"
      },
      "source": [
        "import pandas as pd \n",
        "import os \n",
        "from google.colab import files, drive\n",
        "import glob\n",
        "import re \n",
        "import datetime\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from collections import Counter \n",
        "from catboost import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.experimental.enable_hist_gradient_boosting import *\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.utils import *\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.dummy import * \n",
        "from sklearn.metrics import *\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.neural_network import * \n",
        "from sklearn.tree import * \n",
        "from sklearn.ensemble import *\n",
        "from sklearn.compose import * \n",
        "from sklearn.preprocessing import * \n",
        "from sklearn.model_selection import *\n",
        "import seaborn as sns\n",
        "from sklearn.experimental import enable_hist_gradient_boosting \n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from lightgbm import * \n",
        "from xgboost import *\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.dummy import *\n",
        "#from sklego.pandas_utils import *\n",
        "#from sklego.meta import GroupedPredictor\n",
        "#from sklego.meta import GroupedEstimator\n",
        "from pyts.classification import * \n",
        "from pyts.datasets import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgkzbeto4VNQ"
      },
      "source": [
        "def anscombe(x):\n",
        "    '''\n",
        "    Compute the anscombe variance stabilizing transform.\n",
        "      the input   x   is noisy Poisson-distributed data\n",
        "      the output  fx  has variance approximately equal to 1.\n",
        "    Reference: Anscombe, F. J. (1948), \"The transformation of Poisson,\n",
        "    binomial and negative-binomial data\", Biometrika 35 (3-4): 246-254\n",
        "    '''\n",
        "    return 2.0*np.sqrt(x + 3.0/8.0)\n",
        "\n",
        "def inverse_anscombe(z):\n",
        "    '''\n",
        "    Compute the inverse transform using an approximation of the exact\n",
        "    unbiased inverse.\n",
        "    Reference: Makitalo, M., & Foi, A. (2011). A closed-form\n",
        "    approximation of the exact unbiased inverse of the Anscombe\n",
        "    variance-stabilizing transformation. Image Processing.\n",
        "    '''\n",
        "    return (z/2.0)**2 - 3.0/8.0\n",
        "\n",
        "def identity(x):\n",
        "  return x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0gkE8iqz_RQ",
        "outputId": "b177c46d-1768-4a80-a4ab-bac17b1482e9"
      },
      "source": [
        "drive.mount(\"MyDrive\")\n",
        "os.chdir(\"MyDrive\")\n",
        "os.chdir(\"MyDrive\")\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtfMp1WrCNnX"
      },
      "source": [
        "# read csv file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgNqd_qy0EwB"
      },
      "source": [
        "#files.upload()\n",
        "#data1 = pd.read_csv(\"NIFTY_2017.csv\", header = [0], index_col = 0)\n",
        "data2 = pd.read_csv(\"NIFTY_2018.csv\", header = [0], index_col = 0)\n",
        "data3 = pd.read_csv(\"NIFTY_2019.csv\", header = [0], index_col = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYE-KnotRepo"
      },
      "source": [
        "data = pd.concat([data2, data3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Ngh2wRYt9a"
      },
      "source": [
        "unique_dates = np.unique(data.Date)\n",
        "#print(unique_dates)\n",
        "unique_dates = list(unique_dates)\n",
        "#print(unique_dates[0])\n",
        "TS = [] \n",
        "for d in unique_dates[0:]:\n",
        " ts = data[data.Date == d].Close.values\n",
        " TS.append(ts)\n",
        "#TS[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSnflbHJsdfG",
        "outputId": "14f2acbd-c188-451f-cb5a-e0dcbbc50e9a"
      },
      "source": [
        "lens_of_ts = [len(ts) for ts in TS]\n",
        "Counter(lens_of_ts) \n",
        "#TS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({63: 2,\n",
              "         372: 1,\n",
              "         373: 1,\n",
              "         375: 39,\n",
              "         376: 1,\n",
              "         377: 34,\n",
              "         378: 291,\n",
              "         379: 116,\n",
              "         380: 6})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9eV7usfRs2h",
        "outputId": "f420b1d0-2085-4e9e-d238-3061fa848177"
      },
      "source": [
        "print(\"total number of series\", len(TS))\n",
        "drops = [] \n",
        "for i in range(len(TS)):\n",
        "  if lens_of_ts[i] < 372:\n",
        "    drops.append(i)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of series 491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwpsz3QGdQ3E",
        "outputId": "95f01021-15b3-4e7f-cc9c-dedc9da819fa"
      },
      "source": [
        "drops\n",
        "TS.pop(drops[0])\n",
        "TS.pop(drops[1] - 1)\n",
        "# TS.pop(drops[2] - 2)\n",
        "# TS.pop(drops[3] - 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11662.25, 11661.1 , 11652.3 , 11639.1 , 11627.85, 11637.1 ,\n",
              "       11641.2 , 11640.25, 11644.3 , 11644.9 , 11639.6 , 11639.3 ,\n",
              "       11636.3 , 11635.85, 11637.15, 11636.3 , 11636.4 , 11638.25,\n",
              "       11642.  , 11643.15, 11643.35, 11642.6 , 11636.3 , 11632.85,\n",
              "       11633.05, 11633.  , 11635.6 , 11638.15, 11639.45, 11639.9 ,\n",
              "       11639.45, 11639.1 , 11638.75, 11638.5 , 11638.6 , 11640.55,\n",
              "       11640.6 , 11642.3 , 11641.5 , 11640.7 , 11639.35, 11636.65,\n",
              "       11634.6 , 11632.3 , 11631.45, 11632.3 , 11626.45, 11607.55,\n",
              "       11611.9 , 11619.4 , 11621.95, 11622.85, 11623.7 , 11625.2 ,\n",
              "       11627.55, 11627.55, 11628.6 , 11629.15, 11626.45, 11627.  ,\n",
              "       11629.55, 11628.  , 11627.15])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfcbXnRWgYeq",
        "outputId": "57d1ec76-81d8-4bfc-9fde-9990facfa3cf"
      },
      "source": [
        "lens_of_ts = [len(ts) for ts in TS]\n",
        "Counter(lens_of_ts) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({372: 1, 373: 1, 375: 39, 376: 1, 377: 34, 378: 291, 379: 116, 380: 6})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 393
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp1HV9rUIKn_"
      },
      "source": [
        "feats = []\n",
        "for i in range(len(TS)):\n",
        "  feats.append(TS[i][:int(5 * 60)])\n",
        "\n",
        "feats = np.stack(feats)\n",
        "feats.shape\n",
        "normed_features = []\n",
        "for i in range(len(feats)):\n",
        "  normed_features.append(feats[i] - feats[i][0])\n",
        "\n",
        "normed_features = [n/100 for n in normed_features]\n",
        "#normed_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ4n5OvsJTd4",
        "outputId": "11ae0277-e4cf-4df8-d4a1-1f3d60ccee38"
      },
      "source": [
        "targets = [] \n",
        "for i in range(len(TS)):\n",
        "  targets.append(TS[i][-1]) #last term in the series is the target \n",
        "targets\n",
        "print(len(targets))\n",
        "targets = np.array(targets)\n",
        "binary_response = [] \n",
        "for i in range(len(targets)):\n",
        "  if targets[i] > feats[i][0]:  #see if the last term is greater than the first term \n",
        "    binary_response.append(1)\n",
        "  else:\n",
        "    binary_response.append(0)\n",
        "\n",
        "binary_response = np.array(binary_response)\n",
        "binary_response.shape\n",
        "binary_response = binary_response[:,np.newaxis]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZAeXgaeKVjE"
      },
      "source": [
        "D = np.concatenate([normed_features,binary_response], axis = -1)\n",
        "D = pd.DataFrame(D)\n",
        "cols = list(D.columns)\n",
        "cols = [\"F\" + str(col) for col in cols]\n",
        "cols[-1] = \"Target\"\n",
        "cols\n",
        "D.columns = cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "6aERo9NZLA4v",
        "outputId": "a69a7766-3f63-4b18-8d0e-ce3721d7c6e5"
      },
      "source": [
        "D.drop(columns = [\"F0\"], inplace = True)\n",
        "D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "      <th>F29</th>\n",
              "      <th>F30</th>\n",
              "      <th>F31</th>\n",
              "      <th>F32</th>\n",
              "      <th>F33</th>\n",
              "      <th>F34</th>\n",
              "      <th>F35</th>\n",
              "      <th>F36</th>\n",
              "      <th>F37</th>\n",
              "      <th>F38</th>\n",
              "      <th>F39</th>\n",
              "      <th>F40</th>\n",
              "      <th>...</th>\n",
              "      <th>F261</th>\n",
              "      <th>F262</th>\n",
              "      <th>F263</th>\n",
              "      <th>F264</th>\n",
              "      <th>F265</th>\n",
              "      <th>F266</th>\n",
              "      <th>F267</th>\n",
              "      <th>F268</th>\n",
              "      <th>F269</th>\n",
              "      <th>F270</th>\n",
              "      <th>F271</th>\n",
              "      <th>F272</th>\n",
              "      <th>F273</th>\n",
              "      <th>F274</th>\n",
              "      <th>F275</th>\n",
              "      <th>F276</th>\n",
              "      <th>F277</th>\n",
              "      <th>F278</th>\n",
              "      <th>F279</th>\n",
              "      <th>F280</th>\n",
              "      <th>F281</th>\n",
              "      <th>F282</th>\n",
              "      <th>F283</th>\n",
              "      <th>F284</th>\n",
              "      <th>F285</th>\n",
              "      <th>F286</th>\n",
              "      <th>F287</th>\n",
              "      <th>F288</th>\n",
              "      <th>F289</th>\n",
              "      <th>F290</th>\n",
              "      <th>F291</th>\n",
              "      <th>F292</th>\n",
              "      <th>F293</th>\n",
              "      <th>F294</th>\n",
              "      <th>F295</th>\n",
              "      <th>F296</th>\n",
              "      <th>F297</th>\n",
              "      <th>F298</th>\n",
              "      <th>F299</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.0850</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0910</td>\n",
              "      <td>-0.1040</td>\n",
              "      <td>-0.0800</td>\n",
              "      <td>-0.0520</td>\n",
              "      <td>-0.0140</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0320</td>\n",
              "      <td>-0.0420</td>\n",
              "      <td>-0.0380</td>\n",
              "      <td>-0.0560</td>\n",
              "      <td>-0.0790</td>\n",
              "      <td>-0.0840</td>\n",
              "      <td>-0.1140</td>\n",
              "      <td>-0.1170</td>\n",
              "      <td>-0.1100</td>\n",
              "      <td>-0.1290</td>\n",
              "      <td>-0.1480</td>\n",
              "      <td>-0.1070</td>\n",
              "      <td>-0.1170</td>\n",
              "      <td>-0.1260</td>\n",
              "      <td>-0.1300</td>\n",
              "      <td>-0.1230</td>\n",
              "      <td>-0.1010</td>\n",
              "      <td>-0.1080</td>\n",
              "      <td>-0.0850</td>\n",
              "      <td>-0.0870</td>\n",
              "      <td>-0.0790</td>\n",
              "      <td>-0.0800</td>\n",
              "      <td>-0.0870</td>\n",
              "      <td>-0.078</td>\n",
              "      <td>-0.0680</td>\n",
              "      <td>-0.0650</td>\n",
              "      <td>-0.0540</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0640</td>\n",
              "      <td>-0.0640</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.1690</td>\n",
              "      <td>-0.1790</td>\n",
              "      <td>-0.1690</td>\n",
              "      <td>-0.1740</td>\n",
              "      <td>-0.1820</td>\n",
              "      <td>-0.1850</td>\n",
              "      <td>-0.1920</td>\n",
              "      <td>-0.1900</td>\n",
              "      <td>-0.1940</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.1910</td>\n",
              "      <td>-0.1970</td>\n",
              "      <td>-0.1970</td>\n",
              "      <td>-0.1920</td>\n",
              "      <td>-0.1900</td>\n",
              "      <td>-0.1820</td>\n",
              "      <td>-0.1820</td>\n",
              "      <td>-0.1800</td>\n",
              "      <td>-0.1970</td>\n",
              "      <td>-0.1940</td>\n",
              "      <td>-0.195</td>\n",
              "      <td>-0.1970</td>\n",
              "      <td>-0.1870</td>\n",
              "      <td>-0.1720</td>\n",
              "      <td>-0.1800</td>\n",
              "      <td>-0.1630</td>\n",
              "      <td>-0.1930</td>\n",
              "      <td>-0.1590</td>\n",
              "      <td>-0.1420</td>\n",
              "      <td>-0.1470</td>\n",
              "      <td>-0.1600</td>\n",
              "      <td>-0.1590</td>\n",
              "      <td>-0.1620</td>\n",
              "      <td>-0.1640</td>\n",
              "      <td>-0.1340</td>\n",
              "      <td>-0.1290</td>\n",
              "      <td>-0.1230</td>\n",
              "      <td>-0.1210</td>\n",
              "      <td>-0.0970</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1300</td>\n",
              "      <td>0.1560</td>\n",
              "      <td>0.1510</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>-0.0280</td>\n",
              "      <td>-0.0460</td>\n",
              "      <td>-0.0970</td>\n",
              "      <td>-0.1100</td>\n",
              "      <td>-0.0530</td>\n",
              "      <td>-0.0650</td>\n",
              "      <td>-0.0750</td>\n",
              "      <td>-0.0500</td>\n",
              "      <td>-0.0170</td>\n",
              "      <td>-0.0370</td>\n",
              "      <td>-0.0520</td>\n",
              "      <td>-0.0850</td>\n",
              "      <td>-0.1420</td>\n",
              "      <td>-0.2010</td>\n",
              "      <td>-0.1690</td>\n",
              "      <td>-0.2150</td>\n",
              "      <td>-0.1720</td>\n",
              "      <td>-0.2510</td>\n",
              "      <td>-0.4030</td>\n",
              "      <td>-0.4220</td>\n",
              "      <td>-0.3580</td>\n",
              "      <td>-0.3190</td>\n",
              "      <td>-0.3200</td>\n",
              "      <td>-0.3020</td>\n",
              "      <td>-0.2520</td>\n",
              "      <td>-0.3250</td>\n",
              "      <td>-0.382</td>\n",
              "      <td>-0.4630</td>\n",
              "      <td>-0.4770</td>\n",
              "      <td>-0.4250</td>\n",
              "      <td>-0.3950</td>\n",
              "      <td>-0.3770</td>\n",
              "      <td>-0.3920</td>\n",
              "      <td>-0.3950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3840</td>\n",
              "      <td>-0.3720</td>\n",
              "      <td>-0.3890</td>\n",
              "      <td>-0.3970</td>\n",
              "      <td>-0.4020</td>\n",
              "      <td>-0.4070</td>\n",
              "      <td>-0.3950</td>\n",
              "      <td>-0.3810</td>\n",
              "      <td>-0.3750</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.3280</td>\n",
              "      <td>-0.3250</td>\n",
              "      <td>-0.3200</td>\n",
              "      <td>-0.3220</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.3930</td>\n",
              "      <td>-0.3780</td>\n",
              "      <td>-0.3810</td>\n",
              "      <td>-0.4020</td>\n",
              "      <td>-0.4080</td>\n",
              "      <td>-0.406</td>\n",
              "      <td>-0.4420</td>\n",
              "      <td>-0.4620</td>\n",
              "      <td>-0.4880</td>\n",
              "      <td>-0.5220</td>\n",
              "      <td>-0.5950</td>\n",
              "      <td>-0.5570</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5270</td>\n",
              "      <td>-0.5730</td>\n",
              "      <td>-0.5170</td>\n",
              "      <td>-0.4450</td>\n",
              "      <td>-0.4970</td>\n",
              "      <td>-0.4850</td>\n",
              "      <td>-0.5320</td>\n",
              "      <td>-0.5170</td>\n",
              "      <td>-0.5010</td>\n",
              "      <td>-0.5100</td>\n",
              "      <td>-0.5430</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.0710</td>\n",
              "      <td>-0.1310</td>\n",
              "      <td>-0.1750</td>\n",
              "      <td>-0.1420</td>\n",
              "      <td>-0.1220</td>\n",
              "      <td>-0.1240</td>\n",
              "      <td>-0.1120</td>\n",
              "      <td>-0.0950</td>\n",
              "      <td>-0.0850</td>\n",
              "      <td>-0.1160</td>\n",
              "      <td>-0.0840</td>\n",
              "      <td>-0.1030</td>\n",
              "      <td>-0.1550</td>\n",
              "      <td>-0.1220</td>\n",
              "      <td>-0.1120</td>\n",
              "      <td>-0.2170</td>\n",
              "      <td>-0.1890</td>\n",
              "      <td>-0.1720</td>\n",
              "      <td>-0.1940</td>\n",
              "      <td>-0.1640</td>\n",
              "      <td>-0.1720</td>\n",
              "      <td>-0.1370</td>\n",
              "      <td>-0.1210</td>\n",
              "      <td>-0.1220</td>\n",
              "      <td>-0.1590</td>\n",
              "      <td>-0.1610</td>\n",
              "      <td>-0.1690</td>\n",
              "      <td>-0.1550</td>\n",
              "      <td>-0.1450</td>\n",
              "      <td>-0.1560</td>\n",
              "      <td>-0.1400</td>\n",
              "      <td>-0.1100</td>\n",
              "      <td>-0.068</td>\n",
              "      <td>-0.0290</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>-0.0240</td>\n",
              "      <td>-0.0350</td>\n",
              "      <td>-0.0300</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.1070</td>\n",
              "      <td>-0.0940</td>\n",
              "      <td>-0.0940</td>\n",
              "      <td>-0.0890</td>\n",
              "      <td>-0.1160</td>\n",
              "      <td>-0.1260</td>\n",
              "      <td>-0.1420</td>\n",
              "      <td>-0.1150</td>\n",
              "      <td>-0.1240</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>-0.1600</td>\n",
              "      <td>-0.1570</td>\n",
              "      <td>-0.1640</td>\n",
              "      <td>-0.1490</td>\n",
              "      <td>-0.1820</td>\n",
              "      <td>-0.1840</td>\n",
              "      <td>-0.1800</td>\n",
              "      <td>-0.1550</td>\n",
              "      <td>-0.1450</td>\n",
              "      <td>-0.1230</td>\n",
              "      <td>-0.108</td>\n",
              "      <td>-0.1390</td>\n",
              "      <td>-0.1150</td>\n",
              "      <td>-0.1020</td>\n",
              "      <td>-0.0790</td>\n",
              "      <td>-0.0770</td>\n",
              "      <td>-0.0870</td>\n",
              "      <td>-0.1100</td>\n",
              "      <td>-0.1030</td>\n",
              "      <td>-0.0810</td>\n",
              "      <td>-0.0820</td>\n",
              "      <td>-0.0810</td>\n",
              "      <td>-0.0940</td>\n",
              "      <td>-0.1030</td>\n",
              "      <td>-0.1000</td>\n",
              "      <td>-0.1180</td>\n",
              "      <td>-0.1310</td>\n",
              "      <td>-0.1040</td>\n",
              "      <td>-0.1340</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.0540</td>\n",
              "      <td>-0.0940</td>\n",
              "      <td>-0.0490</td>\n",
              "      <td>-0.0970</td>\n",
              "      <td>-0.1630</td>\n",
              "      <td>-0.2040</td>\n",
              "      <td>-0.1960</td>\n",
              "      <td>-0.2550</td>\n",
              "      <td>-0.2450</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.1830</td>\n",
              "      <td>-0.1960</td>\n",
              "      <td>-0.1610</td>\n",
              "      <td>-0.1510</td>\n",
              "      <td>-0.1180</td>\n",
              "      <td>-0.1990</td>\n",
              "      <td>-0.1750</td>\n",
              "      <td>-0.1690</td>\n",
              "      <td>-0.1520</td>\n",
              "      <td>-0.1220</td>\n",
              "      <td>-0.1590</td>\n",
              "      <td>-0.1370</td>\n",
              "      <td>-0.1250</td>\n",
              "      <td>-0.1140</td>\n",
              "      <td>-0.1240</td>\n",
              "      <td>-0.0790</td>\n",
              "      <td>-0.0610</td>\n",
              "      <td>-0.1040</td>\n",
              "      <td>-0.0740</td>\n",
              "      <td>-0.0940</td>\n",
              "      <td>-0.1030</td>\n",
              "      <td>-0.1110</td>\n",
              "      <td>-0.097</td>\n",
              "      <td>-0.1340</td>\n",
              "      <td>-0.0900</td>\n",
              "      <td>-0.0840</td>\n",
              "      <td>-0.0690</td>\n",
              "      <td>-0.0640</td>\n",
              "      <td>-0.0720</td>\n",
              "      <td>-0.0990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0280</td>\n",
              "      <td>0.0500</td>\n",
              "      <td>0.0640</td>\n",
              "      <td>0.0740</td>\n",
              "      <td>0.0930</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.2040</td>\n",
              "      <td>0.1810</td>\n",
              "      <td>0.1560</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.1580</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.1730</td>\n",
              "      <td>0.1810</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>0.2190</td>\n",
              "      <td>0.2460</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.2070</td>\n",
              "      <td>0.2230</td>\n",
              "      <td>0.231</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>0.2320</td>\n",
              "      <td>0.2610</td>\n",
              "      <td>0.2590</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>0.2380</td>\n",
              "      <td>0.2360</td>\n",
              "      <td>0.2080</td>\n",
              "      <td>0.0640</td>\n",
              "      <td>0.1060</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>0.1490</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.1750</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.0480</td>\n",
              "      <td>-0.0600</td>\n",
              "      <td>-0.0480</td>\n",
              "      <td>-0.0600</td>\n",
              "      <td>0.0220</td>\n",
              "      <td>0.0070</td>\n",
              "      <td>0.0340</td>\n",
              "      <td>0.0390</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>0.0270</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.0290</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0280</td>\n",
              "      <td>0.0650</td>\n",
              "      <td>0.1120</td>\n",
              "      <td>0.1370</td>\n",
              "      <td>0.1320</td>\n",
              "      <td>0.1270</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.1390</td>\n",
              "      <td>0.1350</td>\n",
              "      <td>0.1770</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.1610</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1040</td>\n",
              "      <td>0.0940</td>\n",
              "      <td>0.0770</td>\n",
              "      <td>0.1100</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1260</td>\n",
              "      <td>0.166</td>\n",
              "      <td>0.1720</td>\n",
              "      <td>0.1700</td>\n",
              "      <td>0.2010</td>\n",
              "      <td>0.1920</td>\n",
              "      <td>0.2020</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0330</td>\n",
              "      <td>0.0280</td>\n",
              "      <td>0.0720</td>\n",
              "      <td>0.0570</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.0970</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>0.0820</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>0.0780</td>\n",
              "      <td>0.0800</td>\n",
              "      <td>0.0870</td>\n",
              "      <td>0.0970</td>\n",
              "      <td>0.1080</td>\n",
              "      <td>0.1390</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>0.1270</td>\n",
              "      <td>0.1190</td>\n",
              "      <td>0.118</td>\n",
              "      <td>0.1270</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.1350</td>\n",
              "      <td>0.1310</td>\n",
              "      <td>0.1320</td>\n",
              "      <td>0.1260</td>\n",
              "      <td>0.1020</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>0.0870</td>\n",
              "      <td>0.0650</td>\n",
              "      <td>0.0520</td>\n",
              "      <td>0.0950</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.1370</td>\n",
              "      <td>0.1370</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>0.1570</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>-0.0465</td>\n",
              "      <td>-0.0085</td>\n",
              "      <td>-0.0170</td>\n",
              "      <td>0.0575</td>\n",
              "      <td>0.0470</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0.1015</td>\n",
              "      <td>0.0965</td>\n",
              "      <td>0.0695</td>\n",
              "      <td>0.0905</td>\n",
              "      <td>0.0740</td>\n",
              "      <td>0.0515</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.0985</td>\n",
              "      <td>0.0905</td>\n",
              "      <td>0.0910</td>\n",
              "      <td>0.0985</td>\n",
              "      <td>0.1425</td>\n",
              "      <td>0.1145</td>\n",
              "      <td>0.1110</td>\n",
              "      <td>0.0845</td>\n",
              "      <td>0.0795</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0415</td>\n",
              "      <td>0.0885</td>\n",
              "      <td>0.0560</td>\n",
              "      <td>0.0515</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>0.0310</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.038</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>-0.0185</td>\n",
              "      <td>-0.0115</td>\n",
              "      <td>-0.0395</td>\n",
              "      <td>-0.0270</td>\n",
              "      <td>-0.0445</td>\n",
              "      <td>-0.0240</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2790</td>\n",
              "      <td>-0.2755</td>\n",
              "      <td>-0.2725</td>\n",
              "      <td>-0.2570</td>\n",
              "      <td>-0.2475</td>\n",
              "      <td>-0.2420</td>\n",
              "      <td>-0.2440</td>\n",
              "      <td>-0.2400</td>\n",
              "      <td>-0.2370</td>\n",
              "      <td>-0.220</td>\n",
              "      <td>-0.2275</td>\n",
              "      <td>-0.2310</td>\n",
              "      <td>-0.2645</td>\n",
              "      <td>-0.2715</td>\n",
              "      <td>-0.2725</td>\n",
              "      <td>-0.2655</td>\n",
              "      <td>-0.2705</td>\n",
              "      <td>-0.2930</td>\n",
              "      <td>-0.2915</td>\n",
              "      <td>-0.2895</td>\n",
              "      <td>-0.292</td>\n",
              "      <td>-0.2935</td>\n",
              "      <td>-0.2900</td>\n",
              "      <td>-0.2925</td>\n",
              "      <td>-0.2760</td>\n",
              "      <td>-0.1545</td>\n",
              "      <td>-0.1515</td>\n",
              "      <td>-0.1285</td>\n",
              "      <td>-0.1595</td>\n",
              "      <td>-0.1640</td>\n",
              "      <td>-0.1700</td>\n",
              "      <td>-0.1765</td>\n",
              "      <td>-0.1840</td>\n",
              "      <td>-0.2010</td>\n",
              "      <td>-0.2385</td>\n",
              "      <td>-0.2320</td>\n",
              "      <td>-0.2245</td>\n",
              "      <td>-0.2240</td>\n",
              "      <td>-0.2220</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0870</td>\n",
              "      <td>-0.0200</td>\n",
              "      <td>-0.0325</td>\n",
              "      <td>-0.0445</td>\n",
              "      <td>-0.0135</td>\n",
              "      <td>-0.0180</td>\n",
              "      <td>-0.0405</td>\n",
              "      <td>-0.0820</td>\n",
              "      <td>-0.0800</td>\n",
              "      <td>-0.1065</td>\n",
              "      <td>-0.1160</td>\n",
              "      <td>-0.1255</td>\n",
              "      <td>-0.1075</td>\n",
              "      <td>-0.0650</td>\n",
              "      <td>-0.0560</td>\n",
              "      <td>-0.0230</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0285</td>\n",
              "      <td>0.0385</td>\n",
              "      <td>0.0415</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>-0.0225</td>\n",
              "      <td>-0.0445</td>\n",
              "      <td>-0.0295</td>\n",
              "      <td>-0.0095</td>\n",
              "      <td>-0.0160</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.0275</td>\n",
              "      <td>0.046</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0245</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3660</td>\n",
              "      <td>-0.3545</td>\n",
              "      <td>-0.3490</td>\n",
              "      <td>-0.3425</td>\n",
              "      <td>-0.3440</td>\n",
              "      <td>-0.3405</td>\n",
              "      <td>-0.3595</td>\n",
              "      <td>-0.3555</td>\n",
              "      <td>-0.3735</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>-0.3770</td>\n",
              "      <td>-0.4080</td>\n",
              "      <td>-0.4500</td>\n",
              "      <td>-0.4195</td>\n",
              "      <td>-0.4100</td>\n",
              "      <td>-0.4280</td>\n",
              "      <td>-0.4030</td>\n",
              "      <td>-0.3935</td>\n",
              "      <td>-0.4200</td>\n",
              "      <td>-0.4245</td>\n",
              "      <td>-0.423</td>\n",
              "      <td>-0.4405</td>\n",
              "      <td>-0.4135</td>\n",
              "      <td>-0.4100</td>\n",
              "      <td>-0.4210</td>\n",
              "      <td>-0.4060</td>\n",
              "      <td>-0.4080</td>\n",
              "      <td>-0.4295</td>\n",
              "      <td>-0.4155</td>\n",
              "      <td>-0.4350</td>\n",
              "      <td>-0.4340</td>\n",
              "      <td>-0.4250</td>\n",
              "      <td>-0.4490</td>\n",
              "      <td>-0.4425</td>\n",
              "      <td>-0.4405</td>\n",
              "      <td>-0.4600</td>\n",
              "      <td>-0.4520</td>\n",
              "      <td>-0.4530</td>\n",
              "      <td>-0.4650</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0360</td>\n",
              "      <td>-0.0150</td>\n",
              "      <td>-0.0230</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0475</td>\n",
              "      <td>-0.0400</td>\n",
              "      <td>-0.0580</td>\n",
              "      <td>-0.0730</td>\n",
              "      <td>-0.0965</td>\n",
              "      <td>-0.1270</td>\n",
              "      <td>-0.0985</td>\n",
              "      <td>-0.0380</td>\n",
              "      <td>-0.0100</td>\n",
              "      <td>-0.0295</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0615</td>\n",
              "      <td>0.1075</td>\n",
              "      <td>0.0910</td>\n",
              "      <td>0.0975</td>\n",
              "      <td>0.1270</td>\n",
              "      <td>0.1340</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.0915</td>\n",
              "      <td>0.0730</td>\n",
              "      <td>0.0805</td>\n",
              "      <td>0.0790</td>\n",
              "      <td>0.073</td>\n",
              "      <td>0.0825</td>\n",
              "      <td>0.0920</td>\n",
              "      <td>0.1025</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>0.1350</td>\n",
              "      <td>0.1425</td>\n",
              "      <td>0.1890</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5330</td>\n",
              "      <td>0.5590</td>\n",
              "      <td>0.5735</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.5400</td>\n",
              "      <td>0.5470</td>\n",
              "      <td>0.5590</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.5495</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.5760</td>\n",
              "      <td>0.5670</td>\n",
              "      <td>0.5265</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.5525</td>\n",
              "      <td>0.5610</td>\n",
              "      <td>0.5620</td>\n",
              "      <td>0.5485</td>\n",
              "      <td>0.5400</td>\n",
              "      <td>0.5155</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5115</td>\n",
              "      <td>0.4955</td>\n",
              "      <td>0.4765</td>\n",
              "      <td>0.4660</td>\n",
              "      <td>0.4670</td>\n",
              "      <td>0.4765</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.4890</td>\n",
              "      <td>0.4740</td>\n",
              "      <td>0.4645</td>\n",
              "      <td>0.3870</td>\n",
              "      <td>0.3845</td>\n",
              "      <td>0.3730</td>\n",
              "      <td>0.3945</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.4085</td>\n",
              "      <td>0.4335</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>-0.1015</td>\n",
              "      <td>-0.0085</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>-0.0635</td>\n",
              "      <td>-0.0255</td>\n",
              "      <td>-0.0135</td>\n",
              "      <td>-0.0380</td>\n",
              "      <td>-0.0355</td>\n",
              "      <td>-0.0260</td>\n",
              "      <td>-0.0065</td>\n",
              "      <td>-0.0095</td>\n",
              "      <td>-0.0320</td>\n",
              "      <td>-0.0190</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0830</td>\n",
              "      <td>0.0600</td>\n",
              "      <td>0.0730</td>\n",
              "      <td>0.0795</td>\n",
              "      <td>0.0710</td>\n",
              "      <td>0.0440</td>\n",
              "      <td>0.0545</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0800</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.0715</td>\n",
              "      <td>0.1015</td>\n",
              "      <td>0.0885</td>\n",
              "      <td>0.0745</td>\n",
              "      <td>0.0665</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.0940</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0595</td>\n",
              "      <td>0.0940</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.0455</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3935</td>\n",
              "      <td>-0.4125</td>\n",
              "      <td>-0.4145</td>\n",
              "      <td>-0.4170</td>\n",
              "      <td>-0.4155</td>\n",
              "      <td>-0.4480</td>\n",
              "      <td>-0.4445</td>\n",
              "      <td>-0.4500</td>\n",
              "      <td>-0.4305</td>\n",
              "      <td>-0.443</td>\n",
              "      <td>-0.4490</td>\n",
              "      <td>-0.4345</td>\n",
              "      <td>-0.3975</td>\n",
              "      <td>-0.4135</td>\n",
              "      <td>-0.4205</td>\n",
              "      <td>-0.4280</td>\n",
              "      <td>-0.4275</td>\n",
              "      <td>-0.4325</td>\n",
              "      <td>-0.4540</td>\n",
              "      <td>-0.4805</td>\n",
              "      <td>-0.477</td>\n",
              "      <td>-0.4795</td>\n",
              "      <td>-0.4845</td>\n",
              "      <td>-0.4605</td>\n",
              "      <td>-0.4300</td>\n",
              "      <td>-0.3915</td>\n",
              "      <td>-0.3995</td>\n",
              "      <td>-0.4210</td>\n",
              "      <td>-0.4165</td>\n",
              "      <td>-0.4165</td>\n",
              "      <td>-0.4430</td>\n",
              "      <td>-0.4755</td>\n",
              "      <td>-0.4755</td>\n",
              "      <td>-0.4625</td>\n",
              "      <td>-0.4690</td>\n",
              "      <td>-0.4615</td>\n",
              "      <td>-0.4360</td>\n",
              "      <td>-0.4340</td>\n",
              "      <td>-0.4475</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>-0.1295</td>\n",
              "      <td>-0.1210</td>\n",
              "      <td>-0.1945</td>\n",
              "      <td>-0.1935</td>\n",
              "      <td>-0.1655</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2315</td>\n",
              "      <td>-0.2095</td>\n",
              "      <td>-0.1375</td>\n",
              "      <td>-0.1995</td>\n",
              "      <td>-0.2085</td>\n",
              "      <td>-0.2245</td>\n",
              "      <td>-0.2175</td>\n",
              "      <td>-0.1645</td>\n",
              "      <td>-0.1330</td>\n",
              "      <td>-0.1680</td>\n",
              "      <td>-0.1440</td>\n",
              "      <td>-0.1810</td>\n",
              "      <td>-0.2105</td>\n",
              "      <td>-0.2400</td>\n",
              "      <td>-0.2720</td>\n",
              "      <td>-0.2675</td>\n",
              "      <td>-0.2305</td>\n",
              "      <td>-0.2040</td>\n",
              "      <td>-0.2180</td>\n",
              "      <td>-0.2845</td>\n",
              "      <td>-0.3020</td>\n",
              "      <td>-0.3115</td>\n",
              "      <td>-0.2950</td>\n",
              "      <td>-0.3290</td>\n",
              "      <td>-0.3910</td>\n",
              "      <td>-0.3975</td>\n",
              "      <td>-0.387</td>\n",
              "      <td>-0.3435</td>\n",
              "      <td>-0.3315</td>\n",
              "      <td>-0.3100</td>\n",
              "      <td>-0.3015</td>\n",
              "      <td>-0.3265</td>\n",
              "      <td>-0.3295</td>\n",
              "      <td>-0.3435</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2480</td>\n",
              "      <td>-0.2360</td>\n",
              "      <td>-0.2115</td>\n",
              "      <td>-0.2225</td>\n",
              "      <td>-0.1985</td>\n",
              "      <td>-0.1845</td>\n",
              "      <td>-0.1645</td>\n",
              "      <td>-0.1270</td>\n",
              "      <td>-0.1565</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>-0.1800</td>\n",
              "      <td>-0.1790</td>\n",
              "      <td>-0.1875</td>\n",
              "      <td>-0.1905</td>\n",
              "      <td>-0.2345</td>\n",
              "      <td>-0.2195</td>\n",
              "      <td>-0.2270</td>\n",
              "      <td>-0.2110</td>\n",
              "      <td>-0.2140</td>\n",
              "      <td>-0.2180</td>\n",
              "      <td>-0.211</td>\n",
              "      <td>-0.1910</td>\n",
              "      <td>-0.1955</td>\n",
              "      <td>-0.1865</td>\n",
              "      <td>-0.1885</td>\n",
              "      <td>-0.2150</td>\n",
              "      <td>-0.2345</td>\n",
              "      <td>-0.2400</td>\n",
              "      <td>-0.2360</td>\n",
              "      <td>-0.2165</td>\n",
              "      <td>-0.2060</td>\n",
              "      <td>-0.1995</td>\n",
              "      <td>-0.1840</td>\n",
              "      <td>-0.1860</td>\n",
              "      <td>-0.1720</td>\n",
              "      <td>-0.1920</td>\n",
              "      <td>-0.1950</td>\n",
              "      <td>-0.1995</td>\n",
              "      <td>-0.1760</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>489 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         F1      F2      F3      F4  ...    F297    F298    F299  Target\n",
              "0   -0.0850 -0.0570 -0.0910 -0.1040  ... -0.1230 -0.1210 -0.0970     0.0\n",
              "1    0.1300  0.1560  0.1510  0.0660  ... -0.5010 -0.5100 -0.5430     0.0\n",
              "2   -0.0710 -0.1310 -0.1750 -0.1420  ... -0.1310 -0.1040 -0.1340     0.0\n",
              "3   -0.0540 -0.0940 -0.0490 -0.0970  ...  0.1550  0.2090  0.1750     1.0\n",
              "4   -0.0480 -0.0600 -0.0480 -0.0600  ...  0.1370  0.1520  0.1570     1.0\n",
              "..      ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
              "484 -0.0465 -0.0085 -0.0170  0.0575  ... -0.2245 -0.2240 -0.2220     0.0\n",
              "485  0.0155  0.0870 -0.0200 -0.0325  ... -0.4520 -0.4530 -0.4650     0.0\n",
              "486  0.0115  0.0120  0.0040  0.0260  ...  0.4085  0.4335  0.4290     1.0\n",
              "487 -0.1015 -0.0085  0.0305 -0.0020  ... -0.4360 -0.4340 -0.4475     0.0\n",
              "488 -0.1295 -0.1210 -0.1945 -0.1935  ... -0.1950 -0.1995 -0.1760     0.0\n",
              "\n",
              "[489 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 476
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F00IIyAYlySJ",
        "outputId": "f9d2a1d6-7f65-4865-f91e-7dc24673a435"
      },
      "source": [
        "Dtargs = D.iloc[:,-1] \n",
        "Dtargs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.0\n",
              "1      0.0\n",
              "2      0.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "      ... \n",
              "484    0.0\n",
              "485    0.0\n",
              "486    1.0\n",
              "487    0.0\n",
              "488    0.0\n",
              "Name: Target, Length: 489, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 477
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5jDRA7gnrhn"
      },
      "source": [
        "smoother = LowessSmoother(smooth_fraction=0.05, iterations=4)\n",
        "\n",
        "sdata = smoother.smooth(D.iloc[:,:-1])\n",
        "smoothed_features = sdata.smooth_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvTOPqkbmHaN"
      },
      "source": [
        "Dsmooth = pd.DataFrame(smoothed_features)\n",
        "D_smoothed = pd.concat([Dsmooth, Dtargs], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "TNawM_4C8RfN",
        "outputId": "0d9a1453-58cb-4669-9080-fc97b159f9b5"
      },
      "source": [
        "j = 66\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.plot(smoothed_features[j])\n",
        "plt.plot(D.iloc[j,:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc71ca1e2b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 480
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "1eZVcjdpWhqj",
        "outputId": "46604ddd-a857-4666-801c-0d1797a96bae"
      },
      "source": [
        "Dtrain, Dtest = train_test_split(D_smoothed, train_size = 0.80, shuffle = False)\n",
        "Dtrain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.087921</td>\n",
              "      <td>-0.080214</td>\n",
              "      <td>-0.072694</td>\n",
              "      <td>-0.065534</td>\n",
              "      <td>-0.058896</td>\n",
              "      <td>-0.052837</td>\n",
              "      <td>-0.047195</td>\n",
              "      <td>-0.041314</td>\n",
              "      <td>-0.039432</td>\n",
              "      <td>-0.040124</td>\n",
              "      <td>-0.044387</td>\n",
              "      <td>-0.052155</td>\n",
              "      <td>-0.062451</td>\n",
              "      <td>-0.073907</td>\n",
              "      <td>-0.084853</td>\n",
              "      <td>-0.094379</td>\n",
              "      <td>-0.102563</td>\n",
              "      <td>-0.109536</td>\n",
              "      <td>-0.115024</td>\n",
              "      <td>-0.118614</td>\n",
              "      <td>-0.120257</td>\n",
              "      <td>-0.119932</td>\n",
              "      <td>-0.117881</td>\n",
              "      <td>-0.114591</td>\n",
              "      <td>-0.110489</td>\n",
              "      <td>-0.106034</td>\n",
              "      <td>-0.101584</td>\n",
              "      <td>-0.097050</td>\n",
              "      <td>-0.092068</td>\n",
              "      <td>-0.086814</td>\n",
              "      <td>-0.081778</td>\n",
              "      <td>-0.077398</td>\n",
              "      <td>-0.073802</td>\n",
              "      <td>-0.070809</td>\n",
              "      <td>-0.068154</td>\n",
              "      <td>-0.065244</td>\n",
              "      <td>-0.061620</td>\n",
              "      <td>-0.057579</td>\n",
              "      <td>-0.053867</td>\n",
              "      <td>-0.051060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176594</td>\n",
              "      <td>-0.176349</td>\n",
              "      <td>-0.177118</td>\n",
              "      <td>-0.178812</td>\n",
              "      <td>-0.181101</td>\n",
              "      <td>-0.183595</td>\n",
              "      <td>-0.185965</td>\n",
              "      <td>-0.188103</td>\n",
              "      <td>-0.189880</td>\n",
              "      <td>-0.191072</td>\n",
              "      <td>-0.191474</td>\n",
              "      <td>-0.191206</td>\n",
              "      <td>-0.190700</td>\n",
              "      <td>-0.190275</td>\n",
              "      <td>-0.190069</td>\n",
              "      <td>-0.190029</td>\n",
              "      <td>-0.189916</td>\n",
              "      <td>-0.189447</td>\n",
              "      <td>-0.188603</td>\n",
              "      <td>-0.187549</td>\n",
              "      <td>-0.186551</td>\n",
              "      <td>-0.185322</td>\n",
              "      <td>-0.183307</td>\n",
              "      <td>-0.180228</td>\n",
              "      <td>-0.176346</td>\n",
              "      <td>-0.172226</td>\n",
              "      <td>-0.168493</td>\n",
              "      <td>-0.165398</td>\n",
              "      <td>-0.162569</td>\n",
              "      <td>-0.159509</td>\n",
              "      <td>-0.155905</td>\n",
              "      <td>-0.151752</td>\n",
              "      <td>-0.146459</td>\n",
              "      <td>-0.141097</td>\n",
              "      <td>-0.135681</td>\n",
              "      <td>-0.130130</td>\n",
              "      <td>-0.124395</td>\n",
              "      <td>-0.118454</td>\n",
              "      <td>-0.112293</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.147128</td>\n",
              "      <td>0.120205</td>\n",
              "      <td>0.093951</td>\n",
              "      <td>0.068490</td>\n",
              "      <td>0.043781</td>\n",
              "      <td>0.019660</td>\n",
              "      <td>-0.004184</td>\n",
              "      <td>-0.028330</td>\n",
              "      <td>-0.042949</td>\n",
              "      <td>-0.052267</td>\n",
              "      <td>-0.057151</td>\n",
              "      <td>-0.059750</td>\n",
              "      <td>-0.062366</td>\n",
              "      <td>-0.066588</td>\n",
              "      <td>-0.073179</td>\n",
              "      <td>-0.082621</td>\n",
              "      <td>-0.094921</td>\n",
              "      <td>-0.110661</td>\n",
              "      <td>-0.131556</td>\n",
              "      <td>-0.158597</td>\n",
              "      <td>-0.189803</td>\n",
              "      <td>-0.221103</td>\n",
              "      <td>-0.248976</td>\n",
              "      <td>-0.271440</td>\n",
              "      <td>-0.288242</td>\n",
              "      <td>-0.301417</td>\n",
              "      <td>-0.313616</td>\n",
              "      <td>-0.326362</td>\n",
              "      <td>-0.339045</td>\n",
              "      <td>-0.349982</td>\n",
              "      <td>-0.357937</td>\n",
              "      <td>-0.364105</td>\n",
              "      <td>-0.370933</td>\n",
              "      <td>-0.379213</td>\n",
              "      <td>-0.388091</td>\n",
              "      <td>-0.396130</td>\n",
              "      <td>-0.401911</td>\n",
              "      <td>-0.404345</td>\n",
              "      <td>-0.403449</td>\n",
              "      <td>-0.401983</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.374385</td>\n",
              "      <td>-0.378064</td>\n",
              "      <td>-0.381463</td>\n",
              "      <td>-0.383700</td>\n",
              "      <td>-0.383903</td>\n",
              "      <td>-0.381666</td>\n",
              "      <td>-0.377156</td>\n",
              "      <td>-0.370859</td>\n",
              "      <td>-0.363648</td>\n",
              "      <td>-0.356884</td>\n",
              "      <td>-0.351635</td>\n",
              "      <td>-0.348534</td>\n",
              "      <td>-0.348033</td>\n",
              "      <td>-0.350288</td>\n",
              "      <td>-0.355169</td>\n",
              "      <td>-0.362747</td>\n",
              "      <td>-0.373090</td>\n",
              "      <td>-0.385866</td>\n",
              "      <td>-0.400899</td>\n",
              "      <td>-0.418198</td>\n",
              "      <td>-0.436731</td>\n",
              "      <td>-0.454990</td>\n",
              "      <td>-0.472198</td>\n",
              "      <td>-0.488507</td>\n",
              "      <td>-0.502891</td>\n",
              "      <td>-0.513955</td>\n",
              "      <td>-0.521344</td>\n",
              "      <td>-0.525000</td>\n",
              "      <td>-0.525525</td>\n",
              "      <td>-0.523713</td>\n",
              "      <td>-0.520193</td>\n",
              "      <td>-0.515870</td>\n",
              "      <td>-0.514430</td>\n",
              "      <td>-0.513250</td>\n",
              "      <td>-0.512364</td>\n",
              "      <td>-0.511886</td>\n",
              "      <td>-0.511833</td>\n",
              "      <td>-0.512192</td>\n",
              "      <td>-0.512965</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.127688</td>\n",
              "      <td>-0.125666</td>\n",
              "      <td>-0.123557</td>\n",
              "      <td>-0.121567</td>\n",
              "      <td>-0.119803</td>\n",
              "      <td>-0.118253</td>\n",
              "      <td>-0.116695</td>\n",
              "      <td>-0.114166</td>\n",
              "      <td>-0.112543</td>\n",
              "      <td>-0.113199</td>\n",
              "      <td>-0.117102</td>\n",
              "      <td>-0.123524</td>\n",
              "      <td>-0.131621</td>\n",
              "      <td>-0.140435</td>\n",
              "      <td>-0.148808</td>\n",
              "      <td>-0.155576</td>\n",
              "      <td>-0.160137</td>\n",
              "      <td>-0.162377</td>\n",
              "      <td>-0.162643</td>\n",
              "      <td>-0.161773</td>\n",
              "      <td>-0.160271</td>\n",
              "      <td>-0.157893</td>\n",
              "      <td>-0.154956</td>\n",
              "      <td>-0.152440</td>\n",
              "      <td>-0.150298</td>\n",
              "      <td>-0.148105</td>\n",
              "      <td>-0.145178</td>\n",
              "      <td>-0.140265</td>\n",
              "      <td>-0.132146</td>\n",
              "      <td>-0.120083</td>\n",
              "      <td>-0.104845</td>\n",
              "      <td>-0.088296</td>\n",
              "      <td>-0.072280</td>\n",
              "      <td>-0.057757</td>\n",
              "      <td>-0.045012</td>\n",
              "      <td>-0.033778</td>\n",
              "      <td>-0.024093</td>\n",
              "      <td>-0.016348</td>\n",
              "      <td>-0.010096</td>\n",
              "      <td>-0.003242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.114477</td>\n",
              "      <td>-0.113567</td>\n",
              "      <td>-0.113000</td>\n",
              "      <td>-0.113828</td>\n",
              "      <td>-0.116510</td>\n",
              "      <td>-0.121027</td>\n",
              "      <td>-0.126909</td>\n",
              "      <td>-0.133334</td>\n",
              "      <td>-0.139801</td>\n",
              "      <td>-0.146040</td>\n",
              "      <td>-0.151829</td>\n",
              "      <td>-0.156694</td>\n",
              "      <td>-0.160224</td>\n",
              "      <td>-0.161850</td>\n",
              "      <td>-0.161202</td>\n",
              "      <td>-0.158616</td>\n",
              "      <td>-0.154788</td>\n",
              "      <td>-0.150096</td>\n",
              "      <td>-0.144062</td>\n",
              "      <td>-0.136445</td>\n",
              "      <td>-0.127773</td>\n",
              "      <td>-0.119235</td>\n",
              "      <td>-0.112040</td>\n",
              "      <td>-0.106396</td>\n",
              "      <td>-0.101884</td>\n",
              "      <td>-0.097988</td>\n",
              "      <td>-0.094660</td>\n",
              "      <td>-0.092211</td>\n",
              "      <td>-0.091140</td>\n",
              "      <td>-0.091853</td>\n",
              "      <td>-0.093930</td>\n",
              "      <td>-0.096524</td>\n",
              "      <td>-0.100080</td>\n",
              "      <td>-0.103677</td>\n",
              "      <td>-0.107405</td>\n",
              "      <td>-0.111308</td>\n",
              "      <td>-0.115397</td>\n",
              "      <td>-0.119655</td>\n",
              "      <td>-0.124041</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.063232</td>\n",
              "      <td>-0.083883</td>\n",
              "      <td>-0.103814</td>\n",
              "      <td>-0.122830</td>\n",
              "      <td>-0.140846</td>\n",
              "      <td>-0.157926</td>\n",
              "      <td>-0.174333</td>\n",
              "      <td>-0.190605</td>\n",
              "      <td>-0.196262</td>\n",
              "      <td>-0.198243</td>\n",
              "      <td>-0.196983</td>\n",
              "      <td>-0.193057</td>\n",
              "      <td>-0.187018</td>\n",
              "      <td>-0.179318</td>\n",
              "      <td>-0.171138</td>\n",
              "      <td>-0.163974</td>\n",
              "      <td>-0.158482</td>\n",
              "      <td>-0.154307</td>\n",
              "      <td>-0.150412</td>\n",
              "      <td>-0.145654</td>\n",
              "      <td>-0.139124</td>\n",
              "      <td>-0.131177</td>\n",
              "      <td>-0.122730</td>\n",
              "      <td>-0.115129</td>\n",
              "      <td>-0.108876</td>\n",
              "      <td>-0.103984</td>\n",
              "      <td>-0.100219</td>\n",
              "      <td>-0.097751</td>\n",
              "      <td>-0.096618</td>\n",
              "      <td>-0.096233</td>\n",
              "      <td>-0.096011</td>\n",
              "      <td>-0.095596</td>\n",
              "      <td>-0.094824</td>\n",
              "      <td>-0.093607</td>\n",
              "      <td>-0.092119</td>\n",
              "      <td>-0.090629</td>\n",
              "      <td>-0.088981</td>\n",
              "      <td>-0.087399</td>\n",
              "      <td>-0.086248</td>\n",
              "      <td>-0.085702</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058094</td>\n",
              "      <td>0.067956</td>\n",
              "      <td>0.079877</td>\n",
              "      <td>0.093009</td>\n",
              "      <td>0.106514</td>\n",
              "      <td>0.119604</td>\n",
              "      <td>0.131844</td>\n",
              "      <td>0.143137</td>\n",
              "      <td>0.153340</td>\n",
              "      <td>0.162530</td>\n",
              "      <td>0.170736</td>\n",
              "      <td>0.177551</td>\n",
              "      <td>0.183094</td>\n",
              "      <td>0.188386</td>\n",
              "      <td>0.194467</td>\n",
              "      <td>0.200919</td>\n",
              "      <td>0.206839</td>\n",
              "      <td>0.211597</td>\n",
              "      <td>0.214890</td>\n",
              "      <td>0.217044</td>\n",
              "      <td>0.218948</td>\n",
              "      <td>0.221241</td>\n",
              "      <td>0.224080</td>\n",
              "      <td>0.227250</td>\n",
              "      <td>0.230192</td>\n",
              "      <td>0.231559</td>\n",
              "      <td>0.229897</td>\n",
              "      <td>0.224945</td>\n",
              "      <td>0.217081</td>\n",
              "      <td>0.207151</td>\n",
              "      <td>0.196435</td>\n",
              "      <td>0.186407</td>\n",
              "      <td>0.180368</td>\n",
              "      <td>0.174100</td>\n",
              "      <td>0.167665</td>\n",
              "      <td>0.161505</td>\n",
              "      <td>0.155971</td>\n",
              "      <td>0.151306</td>\n",
              "      <td>0.147634</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.055094</td>\n",
              "      <td>-0.044161</td>\n",
              "      <td>-0.033599</td>\n",
              "      <td>-0.023487</td>\n",
              "      <td>-0.013835</td>\n",
              "      <td>-0.004519</td>\n",
              "      <td>0.004696</td>\n",
              "      <td>0.014241</td>\n",
              "      <td>0.020956</td>\n",
              "      <td>0.027654</td>\n",
              "      <td>0.034999</td>\n",
              "      <td>0.043342</td>\n",
              "      <td>0.052868</td>\n",
              "      <td>0.063191</td>\n",
              "      <td>0.074218</td>\n",
              "      <td>0.085941</td>\n",
              "      <td>0.098435</td>\n",
              "      <td>0.111249</td>\n",
              "      <td>0.123275</td>\n",
              "      <td>0.132929</td>\n",
              "      <td>0.138764</td>\n",
              "      <td>0.140543</td>\n",
              "      <td>0.139171</td>\n",
              "      <td>0.136367</td>\n",
              "      <td>0.133476</td>\n",
              "      <td>0.130897</td>\n",
              "      <td>0.128906</td>\n",
              "      <td>0.127732</td>\n",
              "      <td>0.127763</td>\n",
              "      <td>0.129772</td>\n",
              "      <td>0.134511</td>\n",
              "      <td>0.141984</td>\n",
              "      <td>0.151369</td>\n",
              "      <td>0.161135</td>\n",
              "      <td>0.169645</td>\n",
              "      <td>0.175954</td>\n",
              "      <td>0.180021</td>\n",
              "      <td>0.182417</td>\n",
              "      <td>0.183623</td>\n",
              "      <td>0.183861</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035516</td>\n",
              "      <td>0.039899</td>\n",
              "      <td>0.045654</td>\n",
              "      <td>0.052380</td>\n",
              "      <td>0.059534</td>\n",
              "      <td>0.066278</td>\n",
              "      <td>0.071971</td>\n",
              "      <td>0.076605</td>\n",
              "      <td>0.080354</td>\n",
              "      <td>0.083591</td>\n",
              "      <td>0.086873</td>\n",
              "      <td>0.090444</td>\n",
              "      <td>0.094141</td>\n",
              "      <td>0.097946</td>\n",
              "      <td>0.101975</td>\n",
              "      <td>0.106146</td>\n",
              "      <td>0.110373</td>\n",
              "      <td>0.114656</td>\n",
              "      <td>0.118716</td>\n",
              "      <td>0.122085</td>\n",
              "      <td>0.124337</td>\n",
              "      <td>0.125177</td>\n",
              "      <td>0.124705</td>\n",
              "      <td>0.123093</td>\n",
              "      <td>0.120300</td>\n",
              "      <td>0.116135</td>\n",
              "      <td>0.111230</td>\n",
              "      <td>0.106521</td>\n",
              "      <td>0.102817</td>\n",
              "      <td>0.100675</td>\n",
              "      <td>0.100259</td>\n",
              "      <td>0.101700</td>\n",
              "      <td>0.107819</td>\n",
              "      <td>0.114094</td>\n",
              "      <td>0.120767</td>\n",
              "      <td>0.127917</td>\n",
              "      <td>0.135521</td>\n",
              "      <td>0.143518</td>\n",
              "      <td>0.151844</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>-0.104321</td>\n",
              "      <td>-0.110104</td>\n",
              "      <td>-0.112456</td>\n",
              "      <td>-0.111658</td>\n",
              "      <td>-0.108437</td>\n",
              "      <td>-0.103878</td>\n",
              "      <td>-0.099245</td>\n",
              "      <td>-0.094210</td>\n",
              "      <td>-0.069784</td>\n",
              "      <td>-0.042737</td>\n",
              "      <td>-0.017575</td>\n",
              "      <td>0.002047</td>\n",
              "      <td>0.012898</td>\n",
              "      <td>0.013376</td>\n",
              "      <td>0.004249</td>\n",
              "      <td>-0.010978</td>\n",
              "      <td>-0.027767</td>\n",
              "      <td>-0.042471</td>\n",
              "      <td>-0.050818</td>\n",
              "      <td>-0.049944</td>\n",
              "      <td>-0.040271</td>\n",
              "      <td>-0.025497</td>\n",
              "      <td>-0.009521</td>\n",
              "      <td>0.005514</td>\n",
              "      <td>0.018720</td>\n",
              "      <td>0.029747</td>\n",
              "      <td>0.037088</td>\n",
              "      <td>0.039716</td>\n",
              "      <td>0.038034</td>\n",
              "      <td>0.033472</td>\n",
              "      <td>0.027133</td>\n",
              "      <td>0.019972</td>\n",
              "      <td>0.012981</td>\n",
              "      <td>0.006097</td>\n",
              "      <td>-0.002115</td>\n",
              "      <td>-0.013657</td>\n",
              "      <td>-0.028844</td>\n",
              "      <td>-0.047229</td>\n",
              "      <td>-0.068810</td>\n",
              "      <td>-0.093679</td>\n",
              "      <td>...</td>\n",
              "      <td>0.221505</td>\n",
              "      <td>0.221575</td>\n",
              "      <td>0.226004</td>\n",
              "      <td>0.233203</td>\n",
              "      <td>0.241858</td>\n",
              "      <td>0.251017</td>\n",
              "      <td>0.259415</td>\n",
              "      <td>0.266706</td>\n",
              "      <td>0.273537</td>\n",
              "      <td>0.280844</td>\n",
              "      <td>0.288952</td>\n",
              "      <td>0.296780</td>\n",
              "      <td>0.303317</td>\n",
              "      <td>0.308438</td>\n",
              "      <td>0.311523</td>\n",
              "      <td>0.311845</td>\n",
              "      <td>0.309033</td>\n",
              "      <td>0.302899</td>\n",
              "      <td>0.293564</td>\n",
              "      <td>0.282930</td>\n",
              "      <td>0.273203</td>\n",
              "      <td>0.265696</td>\n",
              "      <td>0.260632</td>\n",
              "      <td>0.257541</td>\n",
              "      <td>0.255935</td>\n",
              "      <td>0.255879</td>\n",
              "      <td>0.258421</td>\n",
              "      <td>0.263823</td>\n",
              "      <td>0.271109</td>\n",
              "      <td>0.279984</td>\n",
              "      <td>0.290059</td>\n",
              "      <td>0.300801</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0.328207</td>\n",
              "      <td>0.342251</td>\n",
              "      <td>0.356470</td>\n",
              "      <td>0.370879</td>\n",
              "      <td>0.385476</td>\n",
              "      <td>0.400229</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>-0.215663</td>\n",
              "      <td>-0.220527</td>\n",
              "      <td>-0.224877</td>\n",
              "      <td>-0.229038</td>\n",
              "      <td>-0.233439</td>\n",
              "      <td>-0.238493</td>\n",
              "      <td>-0.244339</td>\n",
              "      <td>-0.250063</td>\n",
              "      <td>-0.257360</td>\n",
              "      <td>-0.268551</td>\n",
              "      <td>-0.286886</td>\n",
              "      <td>-0.313223</td>\n",
              "      <td>-0.345847</td>\n",
              "      <td>-0.381295</td>\n",
              "      <td>-0.417025</td>\n",
              "      <td>-0.452434</td>\n",
              "      <td>-0.487460</td>\n",
              "      <td>-0.520774</td>\n",
              "      <td>-0.550905</td>\n",
              "      <td>-0.576947</td>\n",
              "      <td>-0.597890</td>\n",
              "      <td>-0.613027</td>\n",
              "      <td>-0.622835</td>\n",
              "      <td>-0.627515</td>\n",
              "      <td>-0.626924</td>\n",
              "      <td>-0.621014</td>\n",
              "      <td>-0.610472</td>\n",
              "      <td>-0.596874</td>\n",
              "      <td>-0.582034</td>\n",
              "      <td>-0.567934</td>\n",
              "      <td>-0.555948</td>\n",
              "      <td>-0.547702</td>\n",
              "      <td>-0.544773</td>\n",
              "      <td>-0.547587</td>\n",
              "      <td>-0.555022</td>\n",
              "      <td>-0.565096</td>\n",
              "      <td>-0.576309</td>\n",
              "      <td>-0.587486</td>\n",
              "      <td>-0.598269</td>\n",
              "      <td>-0.608783</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.196379</td>\n",
              "      <td>-1.193988</td>\n",
              "      <td>-1.188636</td>\n",
              "      <td>-1.181593</td>\n",
              "      <td>-1.173090</td>\n",
              "      <td>-1.162265</td>\n",
              "      <td>-1.148202</td>\n",
              "      <td>-1.129960</td>\n",
              "      <td>-1.107382</td>\n",
              "      <td>-1.081551</td>\n",
              "      <td>-1.055369</td>\n",
              "      <td>-1.031348</td>\n",
              "      <td>-1.010577</td>\n",
              "      <td>-0.992778</td>\n",
              "      <td>-0.978181</td>\n",
              "      <td>-0.967996</td>\n",
              "      <td>-0.963852</td>\n",
              "      <td>-0.966502</td>\n",
              "      <td>-0.974777</td>\n",
              "      <td>-0.986696</td>\n",
              "      <td>-1.000955</td>\n",
              "      <td>-1.016609</td>\n",
              "      <td>-1.033295</td>\n",
              "      <td>-1.050744</td>\n",
              "      <td>-1.067962</td>\n",
              "      <td>-1.082701</td>\n",
              "      <td>-1.093285</td>\n",
              "      <td>-1.099522</td>\n",
              "      <td>-1.102158</td>\n",
              "      <td>-1.101823</td>\n",
              "      <td>-1.097793</td>\n",
              "      <td>-1.089601</td>\n",
              "      <td>-1.075731</td>\n",
              "      <td>-1.062173</td>\n",
              "      <td>-1.048492</td>\n",
              "      <td>-1.034620</td>\n",
              "      <td>-1.020586</td>\n",
              "      <td>-1.006437</td>\n",
              "      <td>-0.992310</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>-0.052456</td>\n",
              "      <td>-0.020034</td>\n",
              "      <td>0.011021</td>\n",
              "      <td>0.041230</td>\n",
              "      <td>0.071156</td>\n",
              "      <td>0.101222</td>\n",
              "      <td>0.131383</td>\n",
              "      <td>0.159686</td>\n",
              "      <td>0.179580</td>\n",
              "      <td>0.196961</td>\n",
              "      <td>0.214974</td>\n",
              "      <td>0.235105</td>\n",
              "      <td>0.257603</td>\n",
              "      <td>0.281395</td>\n",
              "      <td>0.304810</td>\n",
              "      <td>0.326696</td>\n",
              "      <td>0.346467</td>\n",
              "      <td>0.364131</td>\n",
              "      <td>0.379829</td>\n",
              "      <td>0.393114</td>\n",
              "      <td>0.403720</td>\n",
              "      <td>0.412167</td>\n",
              "      <td>0.418743</td>\n",
              "      <td>0.423930</td>\n",
              "      <td>0.428461</td>\n",
              "      <td>0.433465</td>\n",
              "      <td>0.439712</td>\n",
              "      <td>0.446746</td>\n",
              "      <td>0.453440</td>\n",
              "      <td>0.459093</td>\n",
              "      <td>0.463976</td>\n",
              "      <td>0.468275</td>\n",
              "      <td>0.471016</td>\n",
              "      <td>0.470833</td>\n",
              "      <td>0.467166</td>\n",
              "      <td>0.459524</td>\n",
              "      <td>0.447953</td>\n",
              "      <td>0.433587</td>\n",
              "      <td>0.418152</td>\n",
              "      <td>0.403470</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.177508</td>\n",
              "      <td>-0.174455</td>\n",
              "      <td>-0.168511</td>\n",
              "      <td>-0.160162</td>\n",
              "      <td>-0.150248</td>\n",
              "      <td>-0.139580</td>\n",
              "      <td>-0.129351</td>\n",
              "      <td>-0.121027</td>\n",
              "      <td>-0.115292</td>\n",
              "      <td>-0.111653</td>\n",
              "      <td>-0.109569</td>\n",
              "      <td>-0.108735</td>\n",
              "      <td>-0.109174</td>\n",
              "      <td>-0.111228</td>\n",
              "      <td>-0.115439</td>\n",
              "      <td>-0.121776</td>\n",
              "      <td>-0.129307</td>\n",
              "      <td>-0.136798</td>\n",
              "      <td>-0.143412</td>\n",
              "      <td>-0.149128</td>\n",
              "      <td>-0.154408</td>\n",
              "      <td>-0.159800</td>\n",
              "      <td>-0.165192</td>\n",
              "      <td>-0.169599</td>\n",
              "      <td>-0.171798</td>\n",
              "      <td>-0.171069</td>\n",
              "      <td>-0.167635</td>\n",
              "      <td>-0.162648</td>\n",
              "      <td>-0.158254</td>\n",
              "      <td>-0.156708</td>\n",
              "      <td>-0.160132</td>\n",
              "      <td>-0.169015</td>\n",
              "      <td>-0.188730</td>\n",
              "      <td>-0.207714</td>\n",
              "      <td>-0.226675</td>\n",
              "      <td>-0.246272</td>\n",
              "      <td>-0.266918</td>\n",
              "      <td>-0.288849</td>\n",
              "      <td>-0.312047</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>0.062537</td>\n",
              "      <td>0.051695</td>\n",
              "      <td>0.040785</td>\n",
              "      <td>0.029474</td>\n",
              "      <td>0.017672</td>\n",
              "      <td>0.005707</td>\n",
              "      <td>-0.005712</td>\n",
              "      <td>-0.014783</td>\n",
              "      <td>-0.023629</td>\n",
              "      <td>-0.035998</td>\n",
              "      <td>-0.053473</td>\n",
              "      <td>-0.073284</td>\n",
              "      <td>-0.089452</td>\n",
              "      <td>-0.098008</td>\n",
              "      <td>-0.097480</td>\n",
              "      <td>-0.088745</td>\n",
              "      <td>-0.074316</td>\n",
              "      <td>-0.056903</td>\n",
              "      <td>-0.036954</td>\n",
              "      <td>-0.013285</td>\n",
              "      <td>0.014225</td>\n",
              "      <td>0.043452</td>\n",
              "      <td>0.071481</td>\n",
              "      <td>0.096245</td>\n",
              "      <td>0.117125</td>\n",
              "      <td>0.135653</td>\n",
              "      <td>0.154464</td>\n",
              "      <td>0.174324</td>\n",
              "      <td>0.195421</td>\n",
              "      <td>0.217366</td>\n",
              "      <td>0.238105</td>\n",
              "      <td>0.255333</td>\n",
              "      <td>0.268832</td>\n",
              "      <td>0.278594</td>\n",
              "      <td>0.283363</td>\n",
              "      <td>0.281516</td>\n",
              "      <td>0.273758</td>\n",
              "      <td>0.262517</td>\n",
              "      <td>0.250585</td>\n",
              "      <td>0.239583</td>\n",
              "      <td>...</td>\n",
              "      <td>0.628605</td>\n",
              "      <td>0.617563</td>\n",
              "      <td>0.602859</td>\n",
              "      <td>0.583996</td>\n",
              "      <td>0.561058</td>\n",
              "      <td>0.535895</td>\n",
              "      <td>0.511279</td>\n",
              "      <td>0.488486</td>\n",
              "      <td>0.467187</td>\n",
              "      <td>0.447449</td>\n",
              "      <td>0.430843</td>\n",
              "      <td>0.419096</td>\n",
              "      <td>0.413503</td>\n",
              "      <td>0.415139</td>\n",
              "      <td>0.424001</td>\n",
              "      <td>0.437898</td>\n",
              "      <td>0.454172</td>\n",
              "      <td>0.470494</td>\n",
              "      <td>0.486471</td>\n",
              "      <td>0.502664</td>\n",
              "      <td>0.518751</td>\n",
              "      <td>0.533554</td>\n",
              "      <td>0.546608</td>\n",
              "      <td>0.557784</td>\n",
              "      <td>0.567081</td>\n",
              "      <td>0.574637</td>\n",
              "      <td>0.580874</td>\n",
              "      <td>0.586320</td>\n",
              "      <td>0.591184</td>\n",
              "      <td>0.594483</td>\n",
              "      <td>0.593989</td>\n",
              "      <td>0.588886</td>\n",
              "      <td>0.577771</td>\n",
              "      <td>0.567112</td>\n",
              "      <td>0.556756</td>\n",
              "      <td>0.546334</td>\n",
              "      <td>0.535487</td>\n",
              "      <td>0.523943</td>\n",
              "      <td>0.511679</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>-0.070789</td>\n",
              "      <td>-0.055422</td>\n",
              "      <td>-0.040497</td>\n",
              "      <td>-0.025985</td>\n",
              "      <td>-0.011692</td>\n",
              "      <td>0.002616</td>\n",
              "      <td>0.017254</td>\n",
              "      <td>0.032848</td>\n",
              "      <td>0.046665</td>\n",
              "      <td>0.057940</td>\n",
              "      <td>0.067273</td>\n",
              "      <td>0.075991</td>\n",
              "      <td>0.084512</td>\n",
              "      <td>0.092852</td>\n",
              "      <td>0.101291</td>\n",
              "      <td>0.109028</td>\n",
              "      <td>0.113489</td>\n",
              "      <td>0.112905</td>\n",
              "      <td>0.107250</td>\n",
              "      <td>0.097212</td>\n",
              "      <td>0.083724</td>\n",
              "      <td>0.067856</td>\n",
              "      <td>0.049774</td>\n",
              "      <td>0.029090</td>\n",
              "      <td>0.006255</td>\n",
              "      <td>-0.016818</td>\n",
              "      <td>-0.037942</td>\n",
              "      <td>-0.055844</td>\n",
              "      <td>-0.069780</td>\n",
              "      <td>-0.079796</td>\n",
              "      <td>-0.088012</td>\n",
              "      <td>-0.096108</td>\n",
              "      <td>-0.104280</td>\n",
              "      <td>-0.112121</td>\n",
              "      <td>-0.118799</td>\n",
              "      <td>-0.123561</td>\n",
              "      <td>-0.126120</td>\n",
              "      <td>-0.126455</td>\n",
              "      <td>-0.124659</td>\n",
              "      <td>-0.121048</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.819688</td>\n",
              "      <td>-0.828305</td>\n",
              "      <td>-0.838306</td>\n",
              "      <td>-0.850219</td>\n",
              "      <td>-0.864012</td>\n",
              "      <td>-0.879082</td>\n",
              "      <td>-0.894660</td>\n",
              "      <td>-0.910962</td>\n",
              "      <td>-0.928854</td>\n",
              "      <td>-0.949305</td>\n",
              "      <td>-0.971890</td>\n",
              "      <td>-0.994746</td>\n",
              "      <td>-1.016093</td>\n",
              "      <td>-1.034189</td>\n",
              "      <td>-1.048279</td>\n",
              "      <td>-1.058965</td>\n",
              "      <td>-1.067082</td>\n",
              "      <td>-1.073164</td>\n",
              "      <td>-1.077680</td>\n",
              "      <td>-1.081924</td>\n",
              "      <td>-1.087401</td>\n",
              "      <td>-1.095590</td>\n",
              "      <td>-1.106835</td>\n",
              "      <td>-1.119639</td>\n",
              "      <td>-1.131338</td>\n",
              "      <td>-1.139892</td>\n",
              "      <td>-1.144556</td>\n",
              "      <td>-1.144733</td>\n",
              "      <td>-1.139820</td>\n",
              "      <td>-1.130093</td>\n",
              "      <td>-1.115802</td>\n",
              "      <td>-1.098015</td>\n",
              "      <td>-1.080675</td>\n",
              "      <td>-1.063280</td>\n",
              "      <td>-1.045867</td>\n",
              "      <td>-1.028635</td>\n",
              "      <td>-1.011794</td>\n",
              "      <td>-0.995484</td>\n",
              "      <td>-0.979757</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>391 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2  ...       297       298  Target\n",
              "0   -0.087921 -0.080214 -0.072694  ... -0.118454 -0.112293     0.0\n",
              "1    0.147128  0.120205  0.093951  ... -0.512192 -0.512965     0.0\n",
              "2   -0.127688 -0.125666 -0.123557  ... -0.119655 -0.124041     0.0\n",
              "3   -0.063232 -0.083883 -0.103814  ...  0.151306  0.147634     1.0\n",
              "4   -0.055094 -0.044161 -0.033599  ...  0.143518  0.151844     1.0\n",
              "..        ...       ...       ...  ...       ...       ...     ...\n",
              "386 -0.104321 -0.110104 -0.112456  ...  0.385476  0.400229     1.0\n",
              "387 -0.215663 -0.220527 -0.224877  ... -1.006437 -0.992310     0.0\n",
              "388 -0.052456 -0.020034  0.011021  ... -0.288849 -0.312047     0.0\n",
              "389  0.062537  0.051695  0.040785  ...  0.523943  0.511679     1.0\n",
              "390 -0.070789 -0.055422 -0.040497  ... -0.995484 -0.979757     0.0\n",
              "\n",
              "[391 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hMIWXNTxeFZ"
      },
      "source": [
        "# sktime section\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz0IJ51J1xug"
      },
      "source": [
        "## Creating sktime data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gR1pw_uRmqc_",
        "outputId": "932be45d-a0d8-4f7b-ce51-e1884c5497e5"
      },
      "source": [
        "Xtrain_sktime = pd.DataFrame()\n",
        "train_series_holder = []\n",
        "for i in range(len(Dtrain)): \n",
        "   series = Dtrain.iloc[i,:-1].values\n",
        "   series = pd.Series(series)\n",
        "   train_series_holder.append(series)\n",
        "Xtrain_sktime[\"dim0\"] = train_series_holder\n",
        "Xtrain_sktime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dim0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0     -0.087921\n",
              "1     -0.080214\n",
              "2     -0.07269...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0      0.147128\n",
              "1      0.120205\n",
              "2      0.09395...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0     -0.127688\n",
              "1     -0.125666\n",
              "2     -0.12355...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0     -0.063232\n",
              "1     -0.083883\n",
              "2     -0.10381...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0     -0.055094\n",
              "1     -0.044161\n",
              "2     -0.03359...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>0     -0.104321\n",
              "1     -0.110104\n",
              "2     -0.11245...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>0     -0.215663\n",
              "1     -0.220527\n",
              "2     -0.22487...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>0     -0.052456\n",
              "1     -0.020034\n",
              "2      0.01102...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>0      0.062537\n",
              "1      0.051695\n",
              "2      0.04078...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>0     -0.070789\n",
              "1     -0.055422\n",
              "2     -0.04049...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>391 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  dim0\n",
              "0    0     -0.087921\n",
              "1     -0.080214\n",
              "2     -0.07269...\n",
              "1    0      0.147128\n",
              "1      0.120205\n",
              "2      0.09395...\n",
              "2    0     -0.127688\n",
              "1     -0.125666\n",
              "2     -0.12355...\n",
              "3    0     -0.063232\n",
              "1     -0.083883\n",
              "2     -0.10381...\n",
              "4    0     -0.055094\n",
              "1     -0.044161\n",
              "2     -0.03359...\n",
              "..                                                 ...\n",
              "386  0     -0.104321\n",
              "1     -0.110104\n",
              "2     -0.11245...\n",
              "387  0     -0.215663\n",
              "1     -0.220527\n",
              "2     -0.22487...\n",
              "388  0     -0.052456\n",
              "1     -0.020034\n",
              "2      0.01102...\n",
              "389  0      0.062537\n",
              "1      0.051695\n",
              "2      0.04078...\n",
              "390  0     -0.070789\n",
              "1     -0.055422\n",
              "2     -0.04049...\n",
              "\n",
              "[391 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "J1PPZGf5a2bY",
        "outputId": "31357d35-a056-4523-f2f9-9690916c9c7c"
      },
      "source": [
        "Xtest_sktime = pd.DataFrame()\n",
        "test_series_holder = []\n",
        "for i in range(len(Dtest)): \n",
        "   series = Dtest.iloc[i,:-1].values\n",
        "   series = pd.Series(series)\n",
        "   test_series_holder.append(series)\n",
        "Xtest_sktime[\"dim0\"] = test_series_holder\n",
        "Xtest_sktime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dim0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0     -0.120596\n",
              "1     -0.151784\n",
              "2     -0.18256...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0     -0.356718\n",
              "1     -0.359980\n",
              "2     -0.36343...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0      0.526297\n",
              "1      0.577197\n",
              "2      0.62728...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0     -0.058018\n",
              "1     -0.079853\n",
              "2     -0.10278...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0      0.074243\n",
              "1      0.047033\n",
              "2      0.02082...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0     -0.014659\n",
              "1     -0.001568\n",
              "2      0.01090...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0      0.034412\n",
              "1      0.021494\n",
              "2      0.00865...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0      0.016320\n",
              "1      0.010084\n",
              "2      0.00385...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0     -0.034147\n",
              "1     -0.032443\n",
              "2     -0.03078...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0     -0.151547\n",
              "1     -0.158572\n",
              "2     -0.16519...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 dim0\n",
              "0   0     -0.120596\n",
              "1     -0.151784\n",
              "2     -0.18256...\n",
              "1   0     -0.356718\n",
              "1     -0.359980\n",
              "2     -0.36343...\n",
              "2   0      0.526297\n",
              "1      0.577197\n",
              "2      0.62728...\n",
              "3   0     -0.058018\n",
              "1     -0.079853\n",
              "2     -0.10278...\n",
              "4   0      0.074243\n",
              "1      0.047033\n",
              "2      0.02082...\n",
              "..                                                ...\n",
              "93  0     -0.014659\n",
              "1     -0.001568\n",
              "2      0.01090...\n",
              "94  0      0.034412\n",
              "1      0.021494\n",
              "2      0.00865...\n",
              "95  0      0.016320\n",
              "1      0.010084\n",
              "2      0.00385...\n",
              "96  0     -0.034147\n",
              "1     -0.032443\n",
              "2     -0.03078...\n",
              "97  0     -0.151547\n",
              "1     -0.158572\n",
              "2     -0.16519...\n",
              "\n",
              "[98 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 483
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4babqdtwoh-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd100eb1-95e4-4da0-9db0-863cdc51d68f"
      },
      "source": [
        "ytrain_sktime = Dtrain.iloc[:,-1]\n",
        "ytrain_sktime.shape\n",
        "ytest_sktime = Dtest.iloc[:,-1]\n",
        "print(Xtrain_sktime.shape, ytrain_sktime.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(391, 1) (391,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehq1IABeqxg0"
      },
      "source": [
        "## mrseql classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12YMDTTAyOmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "fa101ef8-75c1-485c-ea24-a532b2f96867"
      },
      "source": [
        "ms = MrSEQLClassifier(seql_mode = \"clf\", symrep = [\"sfa\", \"sax\"])\n",
        "ms.fit(Xtrain_sktime, ytrain_sktime)\n",
        "predicted = ms.predict(Xtest_sktime)\n",
        "print(\"Accuracy with mr-seql: %2.3f\" % accuracy_score(ytest_sktime, predicted))\n",
        "print(\"Matthews CC:%2.3f\" % matthews_corrcoef(ytest_sktime, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-406-5f7a1a8bb695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMrSEQLClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseql_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"sfa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sax\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_sktime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_sktime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_sktime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy with mr-seql: %2.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest_sktime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Matthews CC:%2.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest_sktime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msktime/classification/shapelet_based/mrseql/mrseql.pyx\u001b[0m in \u001b[0;36msktime.classification.shapelet_based.mrseql.mrseql.MrSEQLClassifier.fit\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msktime/classification/shapelet_based/mrseql/mrseql.pyx\u001b[0m in \u001b[0;36msktime.classification.shapelet_based.mrseql.mrseql.MrSEQLClassifier._transform_time_series\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msktime/classification/shapelet_based/mrseql/mrseql.pyx\u001b[0m in \u001b[0;36msktime.classification.shapelet_based.mrseql.mrseql.AdaptedSFA.fit\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sktime/transformations/panel/dictionary_based/_sfa.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_binning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sktime/transformations/panel/dictionary_based/_sfa.py\u001b[0m in \u001b[0;36m_binning\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_KBinsDiscretizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_KBinsDiscretizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sktime/transformations/panel/dictionary_based/_sfa.py\u001b[0m in \u001b[0;36m_mcb\u001b[0;34m(self, dft)\u001b[0m\n\u001b[1;32m    353\u001b[0m             res = [\n\u001b[1;32m    354\u001b[0m                 \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_instances\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_windows_per_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             ]\n\u001b[1;32m    357\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sktime/transformations/panel/dictionary_based/_sfa.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    353\u001b[0m             res = [\n\u001b[1;32m    354\u001b[0m                 \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_instances\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_windows_per_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             ]\n\u001b[1;32m    357\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxOGMQ4d1D4g"
      },
      "source": [
        "## rocket classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VbW7Q9rrQFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee9b7fe-8e02-42b0-9880-f1571c1b200f"
      },
      "source": [
        "rocket = MiniRocket(random_state = 2468)  # by default, ROCKET uses 10,000 kernels\n",
        "trainx_transform = rocket.fit_transform(Xtrain_sktime)\n",
        "trainx_transform.shape\n",
        "valx_transform = rocket.transform(Xtest_sktime)\n",
        "\n",
        "clf = RidgeClassifierCV(alphas = np.logspace(-4,4, num = 100), normalize = True)\n",
        "clf.fit(trainx_transform, ytrain_sktime)\n",
        "predicted = clf.predict(valx_transform)\n",
        "print(\"Accuracy with Rocket: %2.3f\" % accuracy_score(ytest_sktime, predicted))\n",
        "print(\"Matthews CC:%2.3f\" % matthews_corrcoef(ytest_sktime, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy with Rocket: 0.847\n",
            "Matthews CC:0.693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g11xzcAYk39L"
      },
      "source": [
        "## time series forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPi2cto6gt6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5c1518-542d-4729-f016-82296959622d"
      },
      "source": [
        "steps = [\n",
        "    (\n",
        "        \"extract\",\n",
        "        RandomIntervalFeatureExtractor(\n",
        "            n_intervals = \"sqrt\", features=[np.mean, np.std, _slope]\n",
        "        ),\n",
        "    ),\n",
        "    (\"clf\", DecisionTreeClassifier()),\n",
        "]\n",
        "time_series_tree = Pipeline(steps)\n",
        "\n",
        "tsf = TimeSeriesForestClassifier(\n",
        "    estimator=time_series_tree,\n",
        "    n_estimators = 100,\n",
        "    criterion = \"entropy\",\n",
        "    bootstrap = True,\n",
        "    oob_score = True,\n",
        "    random_state = 2222,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "\n",
        "tsf.fit(Xtrain_sktime, ytrain_sktime)\n",
        "tsf.score(Xtest_sktime, ytest_sktime)\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy_score(ytest_sktime, tsf.predict(Xtest_sktime))))\n",
        "print(\"MCC: {:.3f}\".format(matthews_corrcoef(ytest_sktime, tsf.predict(Xtest_sktime))))\n",
        "#print(\"AUC ROC\", roc_auc_score(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "#print(\"F1 score\", f1_score(ytest_sktime, tsf.predict(Xtest_sktime)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.857\n",
            "MCC: 0.713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h30Mz4G4W9Bu"
      },
      "source": [
        "## other sktime learners\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65QyGHhZFKoK"
      },
      "source": [
        "tsf = RandomIntervalSpectralForest(n_estimators = 50)\n",
        "tsf.fit(Xtrain_sktime, ytrain_sktime)\n",
        "tsf.score(Xtest_sktime, ytest_sktime)\n",
        "print(\"Accuracy:  \", accuracy_score(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"MCC:  \", matthews_corrcoef(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"AUC ROC\", roc_auc_score(y_test, tsf.predict(Xtest_sktime)))\n",
        "print(\"F1 score\", f1_score(ytest_sktime, tsf.predict(Xtest_sktime)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmGqcXgtFzHF",
        "outputId": "c7e026a1-0cbc-47ce-f9fa-8dde67b688aa"
      },
      "source": [
        "tsf = IndividualBOSS(window_size = 80, word_length = 6, norm = False, alphabet_size = 3)\n",
        "tsf.fit(Xtrain_sktime, ytrain_sktime)\n",
        "tsf.score(Xtest_sktime, ytest_sktime)\n",
        "print(\"Accuracy:  \", accuracy_score(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"MCC:  \", matthews_corrcoef(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"AUC ROC\", roc_auc_score(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"F1 score\", f1_score(ytest_sktime, tsf.predict(Xtest_sktime)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:   0.7551020408163265\n",
            "MCC:   0.5053204750958046\n",
            "AUC ROC 0.750104821802935\n",
            "F1 score 0.7209302325581395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0j16FAYGrly"
      },
      "source": [
        "tsf = WEASEL()\n",
        "tsf.fit(Xtrain_sktime, ytrain_sktime)\n",
        "tsf.score(Xtest_sktime, ytest_sktime)\n",
        "print(\"Accuracy:  \", accuracy_score(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"MCC:  \", matthews_corrcoef(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"AUC ROC\", roc_auc_score(ytest_sktime, tsf.predict(Xtest_sktime)))\n",
        "print(\"F1 score\", f1_score(ytest_sktime, tsf.predict(Xtest_sktime)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAmtwffhVxfb"
      },
      "source": [
        "# regular and pyts methods\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yZXB68NV23n",
        "outputId": "ffe63136-99f6-490b-e46f-22d86c27130a"
      },
      "source": [
        "X_train = Dtrain.iloc[:,:-1] \n",
        "X_test = Dtest.iloc[:,:-1]\n",
        "y_train = Dtrain.iloc[:,-1]\n",
        "y_test = Dtest.iloc[:,-1]\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(391, 299) (391,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "trwzr955sbbW",
        "outputId": "9388367c-d314-49c7-e61e-563ae6a0ee62"
      },
      "source": [
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_train.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>259</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.166407</td>\n",
              "      <td>-0.164924</td>\n",
              "      <td>-0.164377</td>\n",
              "      <td>-0.164563</td>\n",
              "      <td>-0.165191</td>\n",
              "      <td>-0.166022</td>\n",
              "      <td>-0.166937</td>\n",
              "      <td>-0.168714</td>\n",
              "      <td>-0.175474</td>\n",
              "      <td>-0.183223</td>\n",
              "      <td>-0.190516</td>\n",
              "      <td>-0.196281</td>\n",
              "      <td>-0.200783</td>\n",
              "      <td>-0.204623</td>\n",
              "      <td>-0.208477</td>\n",
              "      <td>-0.213011</td>\n",
              "      <td>-0.219183</td>\n",
              "      <td>-0.227494</td>\n",
              "      <td>-0.237229</td>\n",
              "      <td>-0.247512</td>\n",
              "      <td>-0.257218</td>\n",
              "      <td>-0.265363</td>\n",
              "      <td>-0.270575</td>\n",
              "      <td>-0.271937</td>\n",
              "      <td>-0.269388</td>\n",
              "      <td>-0.263653</td>\n",
              "      <td>-0.255540</td>\n",
              "      <td>-0.245868</td>\n",
              "      <td>-0.235007</td>\n",
              "      <td>-0.222981</td>\n",
              "      <td>-0.210780</td>\n",
              "      <td>-0.199504</td>\n",
              "      <td>-0.189412</td>\n",
              "      <td>-0.180361</td>\n",
              "      <td>-0.171750</td>\n",
              "      <td>-0.163018</td>\n",
              "      <td>-0.154320</td>\n",
              "      <td>-0.146134</td>\n",
              "      <td>-0.138916</td>\n",
              "      <td>-0.132330</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.741481</td>\n",
              "      <td>-0.753966</td>\n",
              "      <td>-0.764906</td>\n",
              "      <td>-0.773109</td>\n",
              "      <td>-0.777222</td>\n",
              "      <td>-0.775813</td>\n",
              "      <td>-0.768667</td>\n",
              "      <td>-0.757503</td>\n",
              "      <td>-0.744368</td>\n",
              "      <td>-0.729835</td>\n",
              "      <td>-0.713533</td>\n",
              "      <td>-0.695506</td>\n",
              "      <td>-0.676072</td>\n",
              "      <td>-0.655114</td>\n",
              "      <td>-0.632723</td>\n",
              "      <td>-0.609562</td>\n",
              "      <td>-0.586295</td>\n",
              "      <td>-0.562455</td>\n",
              "      <td>-0.537897</td>\n",
              "      <td>-0.513055</td>\n",
              "      <td>-0.489180</td>\n",
              "      <td>-0.468885</td>\n",
              "      <td>-0.454314</td>\n",
              "      <td>-0.445513</td>\n",
              "      <td>-0.441124</td>\n",
              "      <td>-0.439714</td>\n",
              "      <td>-0.439952</td>\n",
              "      <td>-0.440815</td>\n",
              "      <td>-0.441698</td>\n",
              "      <td>-0.442486</td>\n",
              "      <td>-0.442111</td>\n",
              "      <td>-0.438955</td>\n",
              "      <td>-0.432473</td>\n",
              "      <td>-0.420819</td>\n",
              "      <td>-0.407957</td>\n",
              "      <td>-0.394917</td>\n",
              "      <td>-0.381944</td>\n",
              "      <td>-0.369047</td>\n",
              "      <td>-0.356126</td>\n",
              "      <td>-0.343023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>-0.079362</td>\n",
              "      <td>-0.045394</td>\n",
              "      <td>-0.011981</td>\n",
              "      <td>0.020691</td>\n",
              "      <td>0.052456</td>\n",
              "      <td>0.083365</td>\n",
              "      <td>0.113713</td>\n",
              "      <td>0.144091</td>\n",
              "      <td>0.165232</td>\n",
              "      <td>0.181504</td>\n",
              "      <td>0.192118</td>\n",
              "      <td>0.196655</td>\n",
              "      <td>0.196936</td>\n",
              "      <td>0.194594</td>\n",
              "      <td>0.190161</td>\n",
              "      <td>0.183687</td>\n",
              "      <td>0.175689</td>\n",
              "      <td>0.166966</td>\n",
              "      <td>0.158252</td>\n",
              "      <td>0.150001</td>\n",
              "      <td>0.143089</td>\n",
              "      <td>0.138347</td>\n",
              "      <td>0.134751</td>\n",
              "      <td>0.130909</td>\n",
              "      <td>0.126576</td>\n",
              "      <td>0.122842</td>\n",
              "      <td>0.121240</td>\n",
              "      <td>0.121310</td>\n",
              "      <td>0.120828</td>\n",
              "      <td>0.118072</td>\n",
              "      <td>0.113065</td>\n",
              "      <td>0.107120</td>\n",
              "      <td>0.101740</td>\n",
              "      <td>0.097764</td>\n",
              "      <td>0.094969</td>\n",
              "      <td>0.093159</td>\n",
              "      <td>0.091890</td>\n",
              "      <td>0.091193</td>\n",
              "      <td>0.091748</td>\n",
              "      <td>0.094422</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058505</td>\n",
              "      <td>0.069620</td>\n",
              "      <td>0.081928</td>\n",
              "      <td>0.093580</td>\n",
              "      <td>0.103162</td>\n",
              "      <td>0.109700</td>\n",
              "      <td>0.113315</td>\n",
              "      <td>0.114391</td>\n",
              "      <td>0.112808</td>\n",
              "      <td>0.107888</td>\n",
              "      <td>0.099419</td>\n",
              "      <td>0.088443</td>\n",
              "      <td>0.076363</td>\n",
              "      <td>0.064734</td>\n",
              "      <td>0.054423</td>\n",
              "      <td>0.045054</td>\n",
              "      <td>0.036381</td>\n",
              "      <td>0.028769</td>\n",
              "      <td>0.023328</td>\n",
              "      <td>0.020745</td>\n",
              "      <td>0.021437</td>\n",
              "      <td>0.025178</td>\n",
              "      <td>0.030059</td>\n",
              "      <td>0.033476</td>\n",
              "      <td>0.034443</td>\n",
              "      <td>0.033516</td>\n",
              "      <td>0.030866</td>\n",
              "      <td>0.026313</td>\n",
              "      <td>0.018923</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>-0.004553</td>\n",
              "      <td>-0.016715</td>\n",
              "      <td>-0.026135</td>\n",
              "      <td>-0.028131</td>\n",
              "      <td>-0.029706</td>\n",
              "      <td>-0.031273</td>\n",
              "      <td>-0.032662</td>\n",
              "      <td>-0.033639</td>\n",
              "      <td>-0.033999</td>\n",
              "      <td>-0.033643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>-0.317436</td>\n",
              "      <td>-0.303108</td>\n",
              "      <td>-0.288661</td>\n",
              "      <td>-0.274281</td>\n",
              "      <td>-0.260153</td>\n",
              "      <td>-0.246422</td>\n",
              "      <td>-0.233012</td>\n",
              "      <td>-0.219019</td>\n",
              "      <td>-0.206976</td>\n",
              "      <td>-0.197385</td>\n",
              "      <td>-0.190783</td>\n",
              "      <td>-0.187344</td>\n",
              "      <td>-0.187004</td>\n",
              "      <td>-0.189044</td>\n",
              "      <td>-0.192184</td>\n",
              "      <td>-0.195724</td>\n",
              "      <td>-0.199926</td>\n",
              "      <td>-0.205430</td>\n",
              "      <td>-0.212574</td>\n",
              "      <td>-0.221518</td>\n",
              "      <td>-0.232888</td>\n",
              "      <td>-0.246974</td>\n",
              "      <td>-0.262677</td>\n",
              "      <td>-0.278275</td>\n",
              "      <td>-0.292734</td>\n",
              "      <td>-0.306069</td>\n",
              "      <td>-0.318641</td>\n",
              "      <td>-0.330293</td>\n",
              "      <td>-0.340488</td>\n",
              "      <td>-0.349199</td>\n",
              "      <td>-0.357190</td>\n",
              "      <td>-0.365108</td>\n",
              "      <td>-0.373212</td>\n",
              "      <td>-0.381574</td>\n",
              "      <td>-0.389439</td>\n",
              "      <td>-0.395168</td>\n",
              "      <td>-0.397234</td>\n",
              "      <td>-0.395084</td>\n",
              "      <td>-0.389242</td>\n",
              "      <td>-0.380627</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.512304</td>\n",
              "      <td>-0.521876</td>\n",
              "      <td>-0.529527</td>\n",
              "      <td>-0.534898</td>\n",
              "      <td>-0.538106</td>\n",
              "      <td>-0.539408</td>\n",
              "      <td>-0.538951</td>\n",
              "      <td>-0.536856</td>\n",
              "      <td>-0.533468</td>\n",
              "      <td>-0.529539</td>\n",
              "      <td>-0.525654</td>\n",
              "      <td>-0.522167</td>\n",
              "      <td>-0.519033</td>\n",
              "      <td>-0.516386</td>\n",
              "      <td>-0.514042</td>\n",
              "      <td>-0.511521</td>\n",
              "      <td>-0.508388</td>\n",
              "      <td>-0.504693</td>\n",
              "      <td>-0.501056</td>\n",
              "      <td>-0.498092</td>\n",
              "      <td>-0.495909</td>\n",
              "      <td>-0.493971</td>\n",
              "      <td>-0.491308</td>\n",
              "      <td>-0.486830</td>\n",
              "      <td>-0.479935</td>\n",
              "      <td>-0.471223</td>\n",
              "      <td>-0.462104</td>\n",
              "      <td>-0.453685</td>\n",
              "      <td>-0.445834</td>\n",
              "      <td>-0.437997</td>\n",
              "      <td>-0.430010</td>\n",
              "      <td>-0.422355</td>\n",
              "      <td>-0.415753</td>\n",
              "      <td>-0.410818</td>\n",
              "      <td>-0.406288</td>\n",
              "      <td>-0.401847</td>\n",
              "      <td>-0.397298</td>\n",
              "      <td>-0.392561</td>\n",
              "      <td>-0.387626</td>\n",
              "      <td>-0.382507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 299 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2    ...       296       297       298\n",
              "18  -0.166407 -0.164924 -0.164377  ... -0.369047 -0.356126 -0.343023\n",
              "311 -0.079362 -0.045394 -0.011981  ... -0.033639 -0.033999 -0.033643\n",
              "85  -0.317436 -0.303108 -0.288661  ... -0.392561 -0.387626 -0.382507\n",
              "\n",
              "[3 rows x 299 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh9hlRO8t6vy",
        "outputId": "81a5b9ac-ac47-449c-ef45-c51e45a3de2c"
      },
      "source": [
        "y_train.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18     0.0\n",
              "311    1.0\n",
              "85     0.0\n",
              "Name: Target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGhGgGtP1yrn",
        "outputId": "7d45ce15-183f-45ab-dd58-5fae2af0364f"
      },
      "source": [
        "# saxmod = SAXVSM(window_size = 50, word_size = 5, n_bins = 4, window_step = 5,\n",
        "#                 strategy='uniform')\n",
        "\n",
        "for clf in [\n",
        "            LGBMClassifier(), \n",
        "            XGBClassifier(),\n",
        "            # LogisticRegression(), \n",
        "            # KNeighborsClassifier(),\n",
        "            # RidgeClassifier(), \n",
        "            # MLPClassifier()\n",
        "            ]:\n",
        "  #X_train, y_train = shuffle(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  preds = clf.predict(X_test)\n",
        "  preds.shape, y_test.shape\n",
        "  print(\"accuracy {:.3f}\".format(accuracy_score(y_test,preds)))\n",
        "  print()\n",
        "  print(\"MCC {:.3f}\".format(matthews_corrcoef(y_test, preds)))\n",
        "  print(\"------------------------------------------------------------\")\n",
        "  #print(\"AUC ROC\", roc_auc_score(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.837\n",
            "\n",
            "MCC 0.673\n",
            "------------------------------------------------------------\n",
            "[21:40:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "accuracy 0.847\n",
            "\n",
            "MCC 0.692\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhbVEgBTeeTl"
      },
      "source": [
        "# keras TCN section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6-50cIHtu39"
      },
      "source": [
        "!pip install keras-tcn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iDD9iZe8iUt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tqdm.notebook import tqdm\n",
        "from keras.callbacks import *\n",
        "from keras.optimizers import * \n",
        "from tcn import TCN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_F_AZ0i8-Oy",
        "outputId": "034b09ed-376c-43bd-fe63-eeeabe3f36ab"
      },
      "source": [
        "trainx = X_train.values[:,:,np.newaxis]\n",
        "trainx.shape\n",
        "valx = X_test.values[:,:,np.newaxis]\n",
        "print(valx.shape, y_test.shape)\n",
        "trainy = y_train\n",
        "valy = y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98, 299, 1) (98,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXaC6q9a80eD",
        "outputId": "d2796a6b-ad81-4e1e-9e4b-9ca6e3e0a747"
      },
      "source": [
        "i = Input(shape=(trainx.shape[-2], 1))\n",
        "m = TCN()(i)\n",
        "m = Dense(1, activation = 'sigmoid')(m)\n",
        " \n",
        "early_stopping = EarlyStopping(patience = 50, restore_best_weights=True, min_delta = 0.000)\n",
        "reduceLR = ReduceLROnPlateau(factor = 0.5, patience = 5, min_delta = 0.01)\n",
        "\n",
        "model = Model(inputs=[i], outputs=[m])\n",
        "model.summary()\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = 1e-3))\n",
        "model.reset_states()\n",
        "model.fit(trainx, trainy, \n",
        "          validation_data = (valx, y_test),\n",
        "          shuffle = True,\n",
        "          callbacks = [early_stopping, reduceLR],\n",
        "          batch_size = 64,\n",
        "          epochs = 200)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 299, 1)]          0         \n",
            "_________________________________________________________________\n",
            "tcn_16 (TCN)                 (None, 64)                91136     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 91,201\n",
            "Trainable params: 91,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "7/7 [==============================] - 3s 86ms/step - loss: 1.3130 - val_loss: 0.3674\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3729 - val_loss: 0.2808\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4447 - val_loss: 0.3674\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3540 - val_loss: 0.3473\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3344 - val_loss: 0.3035\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3344 - val_loss: 0.3109\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2862 - val_loss: 0.3208\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2746 - val_loss: 0.3186\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2805 - val_loss: 0.3364\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2535 - val_loss: 0.3315\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2632 - val_loss: 0.3214\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2683 - val_loss: 0.3101\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2745 - val_loss: 0.3136\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2724 - val_loss: 0.3061\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2524 - val_loss: 0.3059\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2421 - val_loss: 0.3070\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2571 - val_loss: 0.3086\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2477 - val_loss: 0.3161\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2546 - val_loss: 0.3106\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2604 - val_loss: 0.3127\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2355 - val_loss: 0.3128\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2518 - val_loss: 0.3137\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2276 - val_loss: 0.3158\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2406 - val_loss: 0.3175\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2393 - val_loss: 0.3185\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2433 - val_loss: 0.3178\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2198 - val_loss: 0.3133\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2345 - val_loss: 0.3125\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2461 - val_loss: 0.3131\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2346 - val_loss: 0.3143\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2380 - val_loss: 0.3145\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2360 - val_loss: 0.3157\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2267 - val_loss: 0.3158\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2376 - val_loss: 0.3167\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2130 - val_loss: 0.3169\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2410 - val_loss: 0.3172\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2283 - val_loss: 0.3168\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2480 - val_loss: 0.3169\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2284 - val_loss: 0.3172\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2575 - val_loss: 0.3169\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2376 - val_loss: 0.3168\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2102 - val_loss: 0.3168\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2359 - val_loss: 0.3170\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2379 - val_loss: 0.3172\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2412 - val_loss: 0.3174\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2223 - val_loss: 0.3176\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2388 - val_loss: 0.3175\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2403 - val_loss: 0.3175\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2200 - val_loss: 0.3175\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2292 - val_loss: 0.3175\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2265 - val_loss: 0.3175\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2459 - val_loss: 0.3176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc6688617f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7aS6wPrAPmw",
        "outputId": "0e8ed1a2-892a-4b9e-fa6f-da810b37c9b7"
      },
      "source": [
        "preds = model.predict(valx)\n",
        "preds = np.round(preds)\n",
        "print(\"MCC {:.3f}\".format(matthews_corrcoef(y_test, preds)))\n",
        "print(\"Acc {:.3f}\".format(accuracy_score(y_test, preds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC 0.715\n",
            "Acc 0.857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAZ9y9lznib6"
      },
      "source": [
        "# pycaret section\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2a2b71cb350d42e088dfcf2de8cb20f5",
            "8761ba48cf1144adbdf251e85e22d006",
            "fc9851dbceed413388b38cbf3f7c8f64"
          ]
        },
        "id": "T22vHYb_30im",
        "outputId": "4375bc58-f3b1-4a97-c46c-a51653672736"
      },
      "source": [
        "from pycaret.classification import * \n",
        "experiment = setup(data = D,\n",
        "                   #train_size = 0.80,\n",
        "                   #test_data = Dtest,\n",
        "                   #pca = True,\n",
        "                   #pca_method = \"linear\",\n",
        "                   #pca_components = .90,\n",
        "                   #feature_selection = True, \n",
        "                   #remove_multicollinearity = True, \n",
        "                   #feature_selection_method = \"boruta\",\n",
        "                   #feature_interaction = True, \n",
        "                   data_split_shuffle = True,\n",
        "                   #create_clusters = True,\n",
        "                   target = \"Target\",\n",
        "                   #normalize = True, \n",
        "                   silent = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>6560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>Target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>0.0: 0, 1.0: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(489, 240)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(342, 66)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(147, 66)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>a804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id              6560\n",
              "1                                   Target            Target\n",
              "2                              Target Type            Binary\n",
              "3                            Label Encoded    0.0: 0, 1.0: 1\n",
              "4                            Original Data        (489, 240)\n",
              "5                           Missing Values             False\n",
              "6                         Numeric Features               239\n",
              "7                     Categorical Features                 0\n",
              "8                         Ordinal Features             False\n",
              "9                High Cardinality Features             False\n",
              "10                 High Cardinality Method              None\n",
              "11                   Transformed Train Set         (342, 66)\n",
              "12                    Transformed Test Set         (147, 66)\n",
              "13                      Shuffle Train-Test              True\n",
              "14                     Stratify Train-Test             False\n",
              "15                          Fold Generator   StratifiedKFold\n",
              "16                             Fold Number                10\n",
              "17                                CPU Jobs                -1\n",
              "18                                 Use GPU             False\n",
              "19                          Log Experiment             False\n",
              "20                         Experiment Name  clf-default-name\n",
              "21                                     USI              a804\n",
              "22                         Imputation Type            simple\n",
              "23          Iterative Imputation Iteration              None\n",
              "24                         Numeric Imputer              mean\n",
              "25      Iterative Imputation Numeric Model              None\n",
              "26                     Categorical Imputer          constant\n",
              "27  Iterative Imputation Categorical Model              None\n",
              "28           Unknown Categoricals Handling    least_frequent\n",
              "29                               Normalize             False\n",
              "30                        Normalize Method              None\n",
              "31                          Transformation             False\n",
              "32                   Transformation Method              None\n",
              "33                                     PCA             False\n",
              "34                              PCA Method              None\n",
              "35                          PCA Components              None\n",
              "36                     Ignore Low Variance             False\n",
              "37                     Combine Rare Levels             False\n",
              "38                    Rare Level Threshold              None\n",
              "39                         Numeric Binning             False\n",
              "40                         Remove Outliers             False\n",
              "41                      Outliers Threshold              None\n",
              "42                Remove Multicollinearity             False\n",
              "43             Multicollinearity Threshold              None\n",
              "44                              Clustering             False\n",
              "45                    Clustering Iteration              None\n",
              "46                     Polynomial Features             False\n",
              "47                       Polynomial Degree              None\n",
              "48                    Trignometry Features             False\n",
              "49                    Polynomial Threshold              None\n",
              "50                          Group Features             False\n",
              "51                       Feature Selection             False\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                           Fix Imbalance             False\n",
              "57                    Fix Imbalance Method             SMOTE"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7fca9b74c488>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/weakref.py\", line 356, in remove\n",
            "    def remove(k, selfref=ref(self)):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mCtvK_BjxrC"
      },
      "source": [
        "get_config(\"X_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2a7970fd23754af2ae8992a0515b4c5c",
            "7557a40ab83940569355ea2d27c74b31",
            "6f872aa58984408aabecab633fdade11"
          ]
        },
        "id": "QeQEiFWMWtD2",
        "outputId": "13a8893e-091e-4ea6-9dcd-dc1cb5a623bc"
      },
      "source": [
        "mods = compare_models(\n",
        "    \n",
        "                      fold = ShuffleSplit(n_splits = 3),\n",
        "                      #cross_validation = False,\n",
        "                      #include = [SGDClassifier(),LogisticRegressionCV(cv = 5), LogisticRegression()],\n",
        "                      n_select = 5, \n",
        "                      turbo = False, \n",
        "                      sort = \"MCC\",\n",
        "                      round = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a7970fd23754af2ae8992a0515b4c5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntProgress(value=0, description='Processing: ', max=94)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Initiated</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>20:22:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Status</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>Compiling Final Models</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Estimator</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>Gaussian Process Classifier</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                           \n",
              "                                                                           \n",
              "Initiated  . . . . . . . . . . . . . . . . . .                     20:22:02\n",
              "Status     . . . . . . . . . . . . . . . . . .       Compiling Final Models\n",
              "Estimator  . . . . . . . . . . . . . . . . . .  Gaussian Process Classifier"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rbfsvm</th>\n",
              "      <td>SVM - Radial Kernel</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpc</th>\n",
              "      <td>Gaussian Process Classifier</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>15.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>MLP Classifier</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy   AUC  Recall  Prec.  \\\n",
              "rbfsvm                SVM - Radial Kernel      0.77  0.84    0.73   0.74   \n",
              "nb                            Naive Bayes      0.75  0.80    0.77   0.70   \n",
              "knn                K Neighbors Classifier      0.75  0.81    0.73   0.71   \n",
              "et                 Extra Trees Classifier      0.75  0.81    0.71   0.72   \n",
              "gpc           Gaussian Process Classifier      0.74  0.81    0.73   0.69   \n",
              "rf               Random Forest Classifier      0.74  0.82    0.70   0.70   \n",
              "lr                    Logistic Regression      0.73  0.83    0.72   0.69   \n",
              "gbc          Gradient Boosting Classifier      0.73  0.80    0.73   0.68   \n",
              "xgboost         Extreme Gradient Boosting      0.72  0.80    0.70   0.67   \n",
              "ada                  Ada Boost Classifier      0.71  0.79    0.76   0.64   \n",
              "lightgbm  Light Gradient Boosting Machine      0.71  0.79    0.70   0.66   \n",
              "lda          Linear Discriminant Analysis      0.70  0.79    0.70   0.65   \n",
              "ridge                    Ridge Classifier      0.70  0.00    0.65   0.66   \n",
              "dt               Decision Tree Classifier      0.65  0.67    0.70   0.59   \n",
              "mlp                        MLP Classifier      0.67  0.77    0.64   0.62   \n",
              "svm                   SVM - Linear Kernel      0.60  0.00    0.53   0.57   \n",
              "qda       Quadratic Discriminant Analysis      0.55  0.54    0.41   0.49   \n",
              "\n",
              "            F1  Kappa   MCC  TT (Sec)  \n",
              "rbfsvm    0.73   0.53  0.54      0.05  \n",
              "nb        0.73   0.50  0.51      0.02  \n",
              "knn       0.72   0.49  0.50      0.49  \n",
              "et        0.71   0.49  0.50      0.32  \n",
              "gpc       0.71   0.47  0.47      0.15  \n",
              "rf        0.69   0.46  0.47      0.38  \n",
              "lr        0.70   0.46  0.46      0.80  \n",
              "gbc       0.70   0.45  0.46      0.38  \n",
              "xgboost   0.68   0.43  0.43     15.95  \n",
              "ada       0.69   0.42  0.43      0.13  \n",
              "lightgbm  0.68   0.42  0.42      0.15  \n",
              "lda       0.67   0.40  0.40      0.02  \n",
              "ridge     0.65   0.39  0.39      0.02  \n",
              "dt        0.64   0.32  0.33      0.02  \n",
              "mlp       0.62   0.33  0.33      0.76  \n",
              "svm       0.53   0.19  0.20      0.02  \n",
              "qda       0.44   0.08  0.08      0.02  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-463-24a490b4e80f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0mturbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0msort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MCC\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                       round = 2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/classification.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, verbose)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m     )\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, verbose, display)\u001b[0m\n\u001b[1;32m   2309\u001b[0m                     \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m                     \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2312\u001b[0m                 )\n\u001b[1;32m   2313\u001b[0m                 \u001b[0msorted_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mcreate_model_supervised\u001b[0;34m(estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, verbose, system, X_train_data, y_train_data, metrics, display, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m         )\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZQAblIEXGUR"
      },
      "source": [
        "evaluate_model(mods[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7b82BisChu5"
      },
      "source": [
        "#!pip install shap\n",
        "interpret_model(mods[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "gdoJTQLbXL0O",
        "outputId": "237dfbed-8fff-4e12-e7ea-9acd0220f880"
      },
      "source": [
        "predict_model(mods[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.788</td>\n",
              "      <td>0.8199</td>\n",
              "      <td>0.7654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7607</td>\n",
              "      <td>0.5705</td>\n",
              "      <td>0.5705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Model  Accuracy     AUC  ...      F1   Kappa     MCC\n",
              "0  K Neighbors Classifier     0.788  0.8199  ...  0.7607  0.5705  0.5705\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "      <th>F29</th>\n",
              "      <th>F30</th>\n",
              "      <th>F31</th>\n",
              "      <th>F32</th>\n",
              "      <th>F33</th>\n",
              "      <th>F34</th>\n",
              "      <th>F35</th>\n",
              "      <th>F36</th>\n",
              "      <th>F37</th>\n",
              "      <th>F38</th>\n",
              "      <th>F39</th>\n",
              "      <th>F40</th>\n",
              "      <th>F41</th>\n",
              "      <th>F42</th>\n",
              "      <th>F45</th>\n",
              "      <th>F50</th>\n",
              "      <th>F52</th>\n",
              "      <th>F54</th>\n",
              "      <th>F56</th>\n",
              "      <th>F59</th>\n",
              "      <th>F68</th>\n",
              "      <th>F75</th>\n",
              "      <th>F78</th>\n",
              "      <th>F81</th>\n",
              "      <th>F83</th>\n",
              "      <th>F89</th>\n",
              "      <th>F94</th>\n",
              "      <th>F103</th>\n",
              "      <th>F112</th>\n",
              "      <th>F116</th>\n",
              "      <th>F183</th>\n",
              "      <th>F198</th>\n",
              "      <th>F219</th>\n",
              "      <th>F231</th>\n",
              "      <th>F234</th>\n",
              "      <th>F235</th>\n",
              "      <th>F237</th>\n",
              "      <th>Target</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0470</td>\n",
              "      <td>-0.0885</td>\n",
              "      <td>-0.0415</td>\n",
              "      <td>0.0365</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.1230</td>\n",
              "      <td>0.1995</td>\n",
              "      <td>0.1835</td>\n",
              "      <td>0.1825</td>\n",
              "      <td>0.2130</td>\n",
              "      <td>0.1920</td>\n",
              "      <td>0.1660</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.1880</td>\n",
              "      <td>0.1575</td>\n",
              "      <td>0.0905</td>\n",
              "      <td>0.1095</td>\n",
              "      <td>0.1295</td>\n",
              "      <td>0.1365</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.1605</td>\n",
              "      <td>0.1610</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.1960</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.2125</td>\n",
              "      <td>0.2130</td>\n",
              "      <td>0.1805</td>\n",
              "      <td>0.1605</td>\n",
              "      <td>0.1955</td>\n",
              "      <td>0.1975</td>\n",
              "      <td>0.2600</td>\n",
              "      <td>0.3035</td>\n",
              "      <td>0.3280</td>\n",
              "      <td>0.3020</td>\n",
              "      <td>0.2955</td>\n",
              "      <td>0.3440</td>\n",
              "      <td>0.3410</td>\n",
              "      <td>0.3585</td>\n",
              "      <td>0.3975</td>\n",
              "      <td>0.5145</td>\n",
              "      <td>0.4870</td>\n",
              "      <td>0.5100</td>\n",
              "      <td>0.4760</td>\n",
              "      <td>0.5270</td>\n",
              "      <td>0.4995</td>\n",
              "      <td>0.4580</td>\n",
              "      <td>0.4405</td>\n",
              "      <td>0.4035</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.3890</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>0.3205</td>\n",
              "      <td>0.3175</td>\n",
              "      <td>0.2690</td>\n",
              "      <td>0.3545</td>\n",
              "      <td>0.4745</td>\n",
              "      <td>0.4225</td>\n",
              "      <td>0.5090</td>\n",
              "      <td>0.5240</td>\n",
              "      <td>0.4765</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.5240</td>\n",
              "      <td>0.5400</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.0755</td>\n",
              "      <td>-0.1120</td>\n",
              "      <td>-0.0790</td>\n",
              "      <td>-0.0820</td>\n",
              "      <td>-0.0730</td>\n",
              "      <td>-0.0545</td>\n",
              "      <td>-0.0780</td>\n",
              "      <td>-0.0795</td>\n",
              "      <td>-0.0415</td>\n",
              "      <td>-0.0305</td>\n",
              "      <td>-0.0205</td>\n",
              "      <td>-0.0150</td>\n",
              "      <td>-0.0575</td>\n",
              "      <td>-0.1520</td>\n",
              "      <td>-0.1495</td>\n",
              "      <td>-0.2855</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>-0.3360</td>\n",
              "      <td>-0.2640</td>\n",
              "      <td>-0.3045</td>\n",
              "      <td>-0.3460</td>\n",
              "      <td>-0.4020</td>\n",
              "      <td>-0.3565</td>\n",
              "      <td>-0.3800</td>\n",
              "      <td>-0.4365</td>\n",
              "      <td>-0.4320</td>\n",
              "      <td>-0.4980</td>\n",
              "      <td>-0.4660</td>\n",
              "      <td>-0.3880</td>\n",
              "      <td>-0.3575</td>\n",
              "      <td>-0.2925</td>\n",
              "      <td>-0.3310</td>\n",
              "      <td>-0.2955</td>\n",
              "      <td>-0.3130</td>\n",
              "      <td>-0.3380</td>\n",
              "      <td>-0.4075</td>\n",
              "      <td>-0.4540</td>\n",
              "      <td>-0.4410</td>\n",
              "      <td>-0.3350</td>\n",
              "      <td>-0.3655</td>\n",
              "      <td>-0.3705</td>\n",
              "      <td>-0.4005</td>\n",
              "      <td>-0.3490</td>\n",
              "      <td>-0.4040</td>\n",
              "      <td>-0.3320</td>\n",
              "      <td>-0.3295</td>\n",
              "      <td>-0.2995</td>\n",
              "      <td>-0.3210</td>\n",
              "      <td>-0.3055</td>\n",
              "      <td>-0.3485</td>\n",
              "      <td>-0.3920</td>\n",
              "      <td>-0.3890</td>\n",
              "      <td>-0.3960</td>\n",
              "      <td>-0.4125</td>\n",
              "      <td>-0.4745</td>\n",
              "      <td>-0.5035</td>\n",
              "      <td>-0.3710</td>\n",
              "      <td>-0.4250</td>\n",
              "      <td>-0.4375</td>\n",
              "      <td>-0.4495</td>\n",
              "      <td>-0.3330</td>\n",
              "      <td>-0.3285</td>\n",
              "      <td>-0.3375</td>\n",
              "      <td>-0.3115</td>\n",
              "      <td>-0.2770</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1210</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.1050</td>\n",
              "      <td>0.1580</td>\n",
              "      <td>0.1545</td>\n",
              "      <td>0.1610</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2230</td>\n",
              "      <td>0.2595</td>\n",
              "      <td>0.2480</td>\n",
              "      <td>0.2930</td>\n",
              "      <td>0.3205</td>\n",
              "      <td>0.2930</td>\n",
              "      <td>0.2570</td>\n",
              "      <td>0.2635</td>\n",
              "      <td>0.2525</td>\n",
              "      <td>0.2320</td>\n",
              "      <td>0.2180</td>\n",
              "      <td>0.2270</td>\n",
              "      <td>0.1735</td>\n",
              "      <td>0.1830</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.1915</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.1920</td>\n",
              "      <td>0.2180</td>\n",
              "      <td>0.2010</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>0.1850</td>\n",
              "      <td>0.2310</td>\n",
              "      <td>0.1670</td>\n",
              "      <td>0.1905</td>\n",
              "      <td>0.2225</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.2850</td>\n",
              "      <td>0.2855</td>\n",
              "      <td>0.3185</td>\n",
              "      <td>0.3155</td>\n",
              "      <td>0.3275</td>\n",
              "      <td>0.3275</td>\n",
              "      <td>0.2800</td>\n",
              "      <td>0.3045</td>\n",
              "      <td>0.3225</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.3880</td>\n",
              "      <td>0.4040</td>\n",
              "      <td>0.3840</td>\n",
              "      <td>0.3955</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>0.4360</td>\n",
              "      <td>0.4250</td>\n",
              "      <td>0.3745</td>\n",
              "      <td>0.3275</td>\n",
              "      <td>0.3080</td>\n",
              "      <td>0.2505</td>\n",
              "      <td>0.2180</td>\n",
              "      <td>0.2215</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.2640</td>\n",
              "      <td>0.3625</td>\n",
              "      <td>0.4030</td>\n",
              "      <td>0.4325</td>\n",
              "      <td>0.4620</td>\n",
              "      <td>0.4530</td>\n",
              "      <td>0.4565</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.1905</td>\n",
              "      <td>-0.3080</td>\n",
              "      <td>-0.2900</td>\n",
              "      <td>-0.2620</td>\n",
              "      <td>-0.3055</td>\n",
              "      <td>-0.4175</td>\n",
              "      <td>-0.3425</td>\n",
              "      <td>-0.4060</td>\n",
              "      <td>-0.3805</td>\n",
              "      <td>-0.4125</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.5405</td>\n",
              "      <td>-0.4815</td>\n",
              "      <td>-0.4500</td>\n",
              "      <td>-0.3875</td>\n",
              "      <td>-0.3370</td>\n",
              "      <td>-0.3560</td>\n",
              "      <td>-0.3365</td>\n",
              "      <td>-0.3165</td>\n",
              "      <td>-0.2580</td>\n",
              "      <td>-0.2865</td>\n",
              "      <td>-0.2965</td>\n",
              "      <td>-0.2445</td>\n",
              "      <td>-0.2115</td>\n",
              "      <td>-0.2400</td>\n",
              "      <td>-0.2780</td>\n",
              "      <td>-0.2585</td>\n",
              "      <td>-0.2600</td>\n",
              "      <td>-0.3335</td>\n",
              "      <td>-0.3160</td>\n",
              "      <td>-0.2920</td>\n",
              "      <td>-0.2890</td>\n",
              "      <td>-0.2780</td>\n",
              "      <td>-0.2655</td>\n",
              "      <td>-0.3120</td>\n",
              "      <td>-0.2725</td>\n",
              "      <td>-0.2875</td>\n",
              "      <td>-0.3180</td>\n",
              "      <td>-0.3095</td>\n",
              "      <td>-0.3565</td>\n",
              "      <td>-0.4020</td>\n",
              "      <td>-0.4150</td>\n",
              "      <td>-0.5040</td>\n",
              "      <td>-0.4435</td>\n",
              "      <td>-0.4005</td>\n",
              "      <td>-0.3385</td>\n",
              "      <td>-0.4060</td>\n",
              "      <td>-0.3355</td>\n",
              "      <td>-0.3435</td>\n",
              "      <td>-0.3715</td>\n",
              "      <td>-0.4200</td>\n",
              "      <td>-0.4595</td>\n",
              "      <td>-0.4520</td>\n",
              "      <td>-0.4065</td>\n",
              "      <td>-0.3365</td>\n",
              "      <td>-0.3655</td>\n",
              "      <td>-0.4360</td>\n",
              "      <td>-0.3840</td>\n",
              "      <td>-0.0970</td>\n",
              "      <td>-0.0880</td>\n",
              "      <td>-0.1815</td>\n",
              "      <td>-0.2760</td>\n",
              "      <td>-0.1825</td>\n",
              "      <td>-0.2055</td>\n",
              "      <td>-0.1750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0405</td>\n",
              "      <td>0.1685</td>\n",
              "      <td>0.0920</td>\n",
              "      <td>0.1830</td>\n",
              "      <td>0.1865</td>\n",
              "      <td>0.1730</td>\n",
              "      <td>0.1330</td>\n",
              "      <td>0.1565</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>0.1675</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1765</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.1315</td>\n",
              "      <td>0.0955</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>0.1365</td>\n",
              "      <td>0.1765</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.1785</td>\n",
              "      <td>0.2165</td>\n",
              "      <td>0.2235</td>\n",
              "      <td>0.2300</td>\n",
              "      <td>0.1805</td>\n",
              "      <td>0.1600</td>\n",
              "      <td>0.1495</td>\n",
              "      <td>0.1135</td>\n",
              "      <td>0.0840</td>\n",
              "      <td>0.1145</td>\n",
              "      <td>0.1055</td>\n",
              "      <td>0.1180</td>\n",
              "      <td>0.1360</td>\n",
              "      <td>0.0955</td>\n",
              "      <td>0.1145</td>\n",
              "      <td>0.1055</td>\n",
              "      <td>0.1100</td>\n",
              "      <td>0.1235</td>\n",
              "      <td>0.1445</td>\n",
              "      <td>0.1190</td>\n",
              "      <td>0.1205</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>0.1155</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>0.1095</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.1775</td>\n",
              "      <td>0.1575</td>\n",
              "      <td>0.1765</td>\n",
              "      <td>0.0750</td>\n",
              "      <td>0.0650</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0855</td>\n",
              "      <td>0.0820</td>\n",
              "      <td>0.1305</td>\n",
              "      <td>0.1150</td>\n",
              "      <td>0.1710</td>\n",
              "      <td>0.1130</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.0385</td>\n",
              "      <td>0.0365</td>\n",
              "      <td>0.0585</td>\n",
              "      <td>0.0220</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.0505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>-0.0465</td>\n",
              "      <td>-0.0085</td>\n",
              "      <td>-0.0170</td>\n",
              "      <td>0.0575</td>\n",
              "      <td>0.0470</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0.1015</td>\n",
              "      <td>0.0965</td>\n",
              "      <td>0.0695</td>\n",
              "      <td>0.0905</td>\n",
              "      <td>0.0740</td>\n",
              "      <td>0.0515</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.0985</td>\n",
              "      <td>0.0905</td>\n",
              "      <td>0.0910</td>\n",
              "      <td>0.0985</td>\n",
              "      <td>0.1425</td>\n",
              "      <td>0.1145</td>\n",
              "      <td>0.1110</td>\n",
              "      <td>0.0845</td>\n",
              "      <td>0.0795</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0415</td>\n",
              "      <td>0.0885</td>\n",
              "      <td>0.0560</td>\n",
              "      <td>0.0515</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>0.0310</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0380</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>-0.0185</td>\n",
              "      <td>-0.0115</td>\n",
              "      <td>-0.0395</td>\n",
              "      <td>-0.0270</td>\n",
              "      <td>-0.0445</td>\n",
              "      <td>-0.0240</td>\n",
              "      <td>-0.0205</td>\n",
              "      <td>-0.0190</td>\n",
              "      <td>-0.0640</td>\n",
              "      <td>-0.0315</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0690</td>\n",
              "      <td>-0.0640</td>\n",
              "      <td>-0.0785</td>\n",
              "      <td>-0.0895</td>\n",
              "      <td>-0.1520</td>\n",
              "      <td>-0.1410</td>\n",
              "      <td>-0.1585</td>\n",
              "      <td>-0.1515</td>\n",
              "      <td>-0.1230</td>\n",
              "      <td>-0.1720</td>\n",
              "      <td>-0.2265</td>\n",
              "      <td>-0.1905</td>\n",
              "      <td>-0.1925</td>\n",
              "      <td>-0.2030</td>\n",
              "      <td>-0.3050</td>\n",
              "      <td>-0.2025</td>\n",
              "      <td>-0.2025</td>\n",
              "      <td>-0.2030</td>\n",
              "      <td>-0.1930</td>\n",
              "      <td>-0.2040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0870</td>\n",
              "      <td>-0.0200</td>\n",
              "      <td>-0.0325</td>\n",
              "      <td>-0.0445</td>\n",
              "      <td>-0.0135</td>\n",
              "      <td>-0.0180</td>\n",
              "      <td>-0.0405</td>\n",
              "      <td>-0.0820</td>\n",
              "      <td>-0.0800</td>\n",
              "      <td>-0.1065</td>\n",
              "      <td>-0.1160</td>\n",
              "      <td>-0.1255</td>\n",
              "      <td>-0.1075</td>\n",
              "      <td>-0.0650</td>\n",
              "      <td>-0.0560</td>\n",
              "      <td>-0.0230</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0285</td>\n",
              "      <td>0.0385</td>\n",
              "      <td>0.0415</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>-0.0225</td>\n",
              "      <td>-0.0445</td>\n",
              "      <td>-0.0295</td>\n",
              "      <td>-0.0095</td>\n",
              "      <td>-0.0160</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.0275</td>\n",
              "      <td>0.0460</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0245</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0210</td>\n",
              "      <td>-0.0235</td>\n",
              "      <td>-0.0045</td>\n",
              "      <td>-0.0010</td>\n",
              "      <td>-0.0050</td>\n",
              "      <td>-0.0110</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>-0.0355</td>\n",
              "      <td>-0.0475</td>\n",
              "      <td>-0.0920</td>\n",
              "      <td>-0.0755</td>\n",
              "      <td>-0.0815</td>\n",
              "      <td>-0.0935</td>\n",
              "      <td>-0.1825</td>\n",
              "      <td>-0.1440</td>\n",
              "      <td>-0.1460</td>\n",
              "      <td>-0.2690</td>\n",
              "      <td>-0.2225</td>\n",
              "      <td>-0.2645</td>\n",
              "      <td>-0.2770</td>\n",
              "      <td>-0.3130</td>\n",
              "      <td>-0.3455</td>\n",
              "      <td>-0.3675</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0360</td>\n",
              "      <td>-0.0150</td>\n",
              "      <td>-0.0230</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0475</td>\n",
              "      <td>-0.0400</td>\n",
              "      <td>-0.0580</td>\n",
              "      <td>-0.0730</td>\n",
              "      <td>-0.0965</td>\n",
              "      <td>-0.1270</td>\n",
              "      <td>-0.0985</td>\n",
              "      <td>-0.0380</td>\n",
              "      <td>-0.0100</td>\n",
              "      <td>-0.0295</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0615</td>\n",
              "      <td>0.1075</td>\n",
              "      <td>0.0910</td>\n",
              "      <td>0.0975</td>\n",
              "      <td>0.1270</td>\n",
              "      <td>0.1340</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.0915</td>\n",
              "      <td>0.0730</td>\n",
              "      <td>0.0805</td>\n",
              "      <td>0.0790</td>\n",
              "      <td>0.0730</td>\n",
              "      <td>0.0825</td>\n",
              "      <td>0.0920</td>\n",
              "      <td>0.1025</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>0.1350</td>\n",
              "      <td>0.1425</td>\n",
              "      <td>0.1890</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1850</td>\n",
              "      <td>0.1540</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>0.1175</td>\n",
              "      <td>0.1270</td>\n",
              "      <td>0.1055</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0960</td>\n",
              "      <td>0.0795</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.2735</td>\n",
              "      <td>0.3135</td>\n",
              "      <td>0.2860</td>\n",
              "      <td>0.3365</td>\n",
              "      <td>0.2910</td>\n",
              "      <td>0.2930</td>\n",
              "      <td>0.4355</td>\n",
              "      <td>0.3735</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.4240</td>\n",
              "      <td>0.4260</td>\n",
              "      <td>0.4175</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>-0.1015</td>\n",
              "      <td>-0.0085</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>-0.0635</td>\n",
              "      <td>-0.0255</td>\n",
              "      <td>-0.0135</td>\n",
              "      <td>-0.0380</td>\n",
              "      <td>-0.0355</td>\n",
              "      <td>-0.0260</td>\n",
              "      <td>-0.0065</td>\n",
              "      <td>-0.0095</td>\n",
              "      <td>-0.0320</td>\n",
              "      <td>-0.0190</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0830</td>\n",
              "      <td>0.0600</td>\n",
              "      <td>0.0730</td>\n",
              "      <td>0.0795</td>\n",
              "      <td>0.0710</td>\n",
              "      <td>0.0440</td>\n",
              "      <td>0.0545</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0800</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.0715</td>\n",
              "      <td>0.1015</td>\n",
              "      <td>0.0885</td>\n",
              "      <td>0.0745</td>\n",
              "      <td>0.0665</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.0940</td>\n",
              "      <td>0.0880</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0595</td>\n",
              "      <td>0.0940</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.0455</td>\n",
              "      <td>-0.0180</td>\n",
              "      <td>-0.0595</td>\n",
              "      <td>-0.0945</td>\n",
              "      <td>-0.0970</td>\n",
              "      <td>-0.0585</td>\n",
              "      <td>-0.0430</td>\n",
              "      <td>-0.0750</td>\n",
              "      <td>-0.0690</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>-0.0070</td>\n",
              "      <td>-0.0415</td>\n",
              "      <td>-0.0240</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.1100</td>\n",
              "      <td>-0.1165</td>\n",
              "      <td>-0.5215</td>\n",
              "      <td>-0.5720</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.4800</td>\n",
              "      <td>-0.3975</td>\n",
              "      <td>-0.4055</td>\n",
              "      <td>-0.4325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>-0.1295</td>\n",
              "      <td>-0.1210</td>\n",
              "      <td>-0.1945</td>\n",
              "      <td>-0.1935</td>\n",
              "      <td>-0.1655</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2315</td>\n",
              "      <td>-0.2095</td>\n",
              "      <td>-0.1375</td>\n",
              "      <td>-0.1995</td>\n",
              "      <td>-0.2085</td>\n",
              "      <td>-0.2245</td>\n",
              "      <td>-0.2175</td>\n",
              "      <td>-0.1645</td>\n",
              "      <td>-0.1330</td>\n",
              "      <td>-0.1680</td>\n",
              "      <td>-0.1440</td>\n",
              "      <td>-0.1810</td>\n",
              "      <td>-0.2105</td>\n",
              "      <td>-0.2400</td>\n",
              "      <td>-0.2720</td>\n",
              "      <td>-0.2675</td>\n",
              "      <td>-0.2305</td>\n",
              "      <td>-0.2040</td>\n",
              "      <td>-0.2180</td>\n",
              "      <td>-0.2845</td>\n",
              "      <td>-0.3020</td>\n",
              "      <td>-0.3115</td>\n",
              "      <td>-0.2950</td>\n",
              "      <td>-0.3290</td>\n",
              "      <td>-0.3910</td>\n",
              "      <td>-0.3975</td>\n",
              "      <td>-0.3870</td>\n",
              "      <td>-0.3435</td>\n",
              "      <td>-0.3315</td>\n",
              "      <td>-0.3100</td>\n",
              "      <td>-0.3015</td>\n",
              "      <td>-0.3265</td>\n",
              "      <td>-0.3295</td>\n",
              "      <td>-0.3435</td>\n",
              "      <td>-0.3525</td>\n",
              "      <td>-0.3620</td>\n",
              "      <td>-0.2980</td>\n",
              "      <td>-0.2580</td>\n",
              "      <td>-0.2975</td>\n",
              "      <td>-0.2995</td>\n",
              "      <td>-0.3485</td>\n",
              "      <td>-0.3630</td>\n",
              "      <td>-0.3075</td>\n",
              "      <td>-0.3390</td>\n",
              "      <td>-0.3410</td>\n",
              "      <td>-0.3250</td>\n",
              "      <td>-0.3175</td>\n",
              "      <td>-0.3830</td>\n",
              "      <td>-0.3955</td>\n",
              "      <td>-0.4190</td>\n",
              "      <td>-0.4320</td>\n",
              "      <td>-0.4035</td>\n",
              "      <td>-0.2725</td>\n",
              "      <td>-0.3025</td>\n",
              "      <td>-0.3230</td>\n",
              "      <td>-0.2485</td>\n",
              "      <td>-0.2295</td>\n",
              "      <td>-0.2260</td>\n",
              "      <td>-0.2225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>184 rows × 68 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         F1      F2      F3      F4      F5  ...    F235    F237  Target  Label  Score\n",
              "0    0.0470 -0.0885 -0.0415  0.0365  0.0895  ...  0.5240  0.5400     1.0    1.0    1.0\n",
              "1   -0.0755 -0.1120 -0.0790 -0.0820 -0.0730  ... -0.3115 -0.2770     0.0    0.0    1.0\n",
              "2    0.1210  0.0125  0.1050  0.1580  0.1545  ...  0.4530  0.4565     1.0    1.0    1.0\n",
              "3   -0.1905 -0.3080 -0.2900 -0.2620 -0.3055  ... -0.2055 -0.1750     1.0    0.0    0.6\n",
              "4    0.0405  0.1685  0.0920  0.1830  0.1865  ...  0.0430  0.0505     0.0    1.0    1.0\n",
              "..      ...     ...     ...     ...     ...  ...     ...     ...     ...    ...    ...\n",
              "179 -0.0465 -0.0085 -0.0170  0.0575  0.0470  ... -0.1930 -0.2040     0.0    0.0    1.0\n",
              "180  0.0155  0.0870 -0.0200 -0.0325 -0.0445  ... -0.3455 -0.3675     0.0    0.0    0.6\n",
              "181  0.0115  0.0120  0.0040  0.0260 -0.0330  ...  0.4260  0.4175     1.0    1.0    1.0\n",
              "182 -0.1015 -0.0085  0.0305 -0.0020 -0.0635  ... -0.4055 -0.4325     0.0    0.0    1.0\n",
              "183 -0.1295 -0.1210 -0.1945 -0.1935 -0.1655  ... -0.2260 -0.2225     0.0    0.0    0.8\n",
              "\n",
              "[184 rows x 68 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "9b2429c1e040476e83a20dd5fc9f29a8",
            "732229ce5f8a4a749c44709db4c1856f",
            "930dc68524d74f49b57ec4ae5e1d3ba5"
          ]
        },
        "id": "Wzzy1L4edXU_",
        "outputId": "9d3d0dd8-242b-4c57-fe73-0999d298d6d9"
      },
      "source": [
        "blender = blend_models([mods[0], mods[1]], \n",
        "                       fold = 2,\n",
        "                       #cross_validation = False\n",
        "                       )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7806</td>\n",
              "      <td>0.8806</td>\n",
              "      <td>0.7191</td>\n",
              "      <td>0.7805</td>\n",
              "      <td>0.7485</td>\n",
              "      <td>0.5545</td>\n",
              "      <td>0.556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8950</td>\n",
              "      <td>0.7416</td>\n",
              "      <td>0.8049</td>\n",
              "      <td>0.7719</td>\n",
              "      <td>0.5944</td>\n",
              "      <td>0.596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7903</td>\n",
              "      <td>0.8878</td>\n",
              "      <td>0.7303</td>\n",
              "      <td>0.7927</td>\n",
              "      <td>0.7602</td>\n",
              "      <td>0.5745</td>\n",
              "      <td>0.576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0122</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa    MCC\n",
              "0       0.7806  0.8806  0.7191  0.7805  0.7485  0.5545  0.556\n",
              "1       0.8000  0.8950  0.7416  0.8049  0.7719  0.5944  0.596\n",
              "Mean    0.7903  0.8878  0.7303  0.7927  0.7602  0.5745  0.576\n",
              "SD      0.0097  0.0072  0.0112  0.0122  0.0117  0.0199  0.020"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "BvCZXn7cd-KE",
        "outputId": "ec0ce6f0-8e37-4c00-c1e6-7a3aa92c479c"
      },
      "source": [
        "predict_model(mods[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.7857</td>\n",
              "      <td>0.8725</td>\n",
              "      <td>0.7111</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.7529</td>\n",
              "      <td>0.5649</td>\n",
              "      <td>0.568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Accuracy     AUC  Recall  Prec.      F1   Kappa    MCC\n",
              "0  Logistic Regression    0.7857  0.8725  0.7111    0.8  0.7529  0.5649  0.568"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F238</th>\n",
              "      <th>Target</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.1925</td>\n",
              "      <td>-0.1020</td>\n",
              "      <td>-0.0445</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.3225</td>\n",
              "      <td>-0.4265</td>\n",
              "      <td>-0.3545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.4250</td>\n",
              "      <td>0.6075</td>\n",
              "      <td>1.3860</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.1605</td>\n",
              "      <td>-0.1290</td>\n",
              "      <td>-0.0190</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0570</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>-0.2425</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>-0.0465</td>\n",
              "      <td>-0.0085</td>\n",
              "      <td>-0.2075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0870</td>\n",
              "      <td>-0.3560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>-0.1015</td>\n",
              "      <td>-0.0085</td>\n",
              "      <td>-0.4520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>-0.1295</td>\n",
              "      <td>-0.1210</td>\n",
              "      <td>-0.2515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        F1      F2    F238 Target Label   Score\n",
              "0  -0.1925 -0.1020 -0.0445    1.0   0.0  0.5412\n",
              "1  -0.3225 -0.4265 -0.3545    0.0   0.0  0.7778\n",
              "2   0.4250  0.6075  1.3860    1.0   1.0  0.9922\n",
              "3  -0.1605 -0.1290 -0.0190    0.0   0.0  0.5181\n",
              "4   0.0570  0.0625 -0.2425    1.0   0.0  0.6883\n",
              "..     ...     ...     ...    ...   ...     ...\n",
              "93 -0.0465 -0.0085 -0.2075    0.0   0.0  0.6667\n",
              "94  0.0155  0.0870 -0.3560    0.0   0.0  0.7663\n",
              "95  0.0115  0.0120  0.4215    1.0   1.0  0.8125\n",
              "96 -0.1015 -0.0085 -0.4520    0.0   0.0  0.8233\n",
              "97 -0.1295 -0.1210 -0.2515    0.0   0.0  0.7028\n",
              "\n",
              "[98 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    }
  ]
}