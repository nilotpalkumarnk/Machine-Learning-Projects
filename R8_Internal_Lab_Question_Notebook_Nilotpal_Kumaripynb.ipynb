{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8 Internal Lab Question Notebook_Nilotpal Kumaripynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHYs6Z84xV8E"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=1tpOCamr9aWz817atPnyXus8w5gJ3mIts\" width=500px>\n",
        "\n",
        "Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QQxgAmWzSye"
      },
      "source": [
        "# Mobile Phone Review Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbwHYUXhxaqD"
      },
      "source": [
        "## Context\n",
        "\n",
        "The product companies can utilize the detailed review comments to gather insights from the end user. Most of the products are sold via e-commerce sites like Flipkart or Amazon where customers can buy a product and give their review about the product on the web site. \n",
        "Product managers can identify the relevant reviews from the website and run a sentiment analysis tool to understand what the sentiments of the customer are. Based on their sentiments, they can identify what users think of the current product. Are they happy? Discontent? \n",
        "They can also come up with a document that lists the features, the team needs to focus on for making the product better. \n",
        "\n",
        "## Objective\n",
        "\n",
        "Given the review data rating label, we will try to get insights about various brands and their ratings using text analytics and build a model to predict the rating and overall sentiment. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI7usguRzeox"
      },
      "source": [
        "### Package version\n",
        "\n",
        "- tensorflow==2.3.0\n",
        "- scikit-learn==0.22.2.post1\n",
        "- pandas==1.0.5\n",
        "- numpy==1.18.5\n",
        "- matplotlib==3.2.2\n",
        "- google==2.0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiMdVjHRH7NR"
      },
      "source": [
        "### Data Dictionary \n",
        "\n",
        "product_data.csv - contains product details\n",
        "- 'asin',  - Product ASIN\n",
        "- 'brand', - Product Brand\n",
        "- 'title', - Product Title\n",
        "- 'url',  - Product URL\n",
        "- 'image', - Product Image URL\n",
        "- 'rating',- Product Avg. Rating\n",
        "- 'reviewUrl' - Product Review Page URL\n",
        "- 'totalReviews' - Product Total Reviews\n",
        "- ‘price’ - Product Price ($)\n",
        "- ‘originalPrice’ - Product Original Price ($)\n",
        " \n",
        "reviews.csv  - contains user review details\n",
        " \n",
        "- 'asin' - Product ASIN\n",
        "- 'name' - Reviewer Name\n",
        "- 'rating' - Reviewer Rating (scale 1 to 5)\n",
        "- 'date'  - Review Date\n",
        "- 'verified' - Valid Customer\n",
        "- 'title'  - Review Title\n",
        "- 'body'  - Review Content\n",
        "- 'helpfulVotes  - Helpful Feedbacks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEn52o8jznJK"
      },
      "source": [
        "## Table of Content\n",
        "\n",
        "1. Import Libraries\n",
        "\n",
        "2. Setting options\n",
        "\n",
        "3. Read Data\n",
        "\n",
        "4. Data Analysis and EDA\n",
        "\n",
        "5. Text preprocessing and Vectorization\n",
        "\n",
        "6. Model building\n",
        "\n",
        "7. Conclusion and Interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Lom6cXzqn7"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZtVstH8zre2"
      },
      "source": [
        "Let us start by mounting the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv9jxv3-R5Xl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv-tZoFjz2WD"
      },
      "source": [
        "Let us check for the version of installed tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiuUVBuDzzn9"
      },
      "source": [
        "# used to supress display of warnings\n",
        "import warnings\n",
        "\n",
        "# os is used to provide a way of using operating system dependent functionality\n",
        "# We use it for setting working folder\n",
        "import os\n",
        "\n",
        "# Pandas is used for data manipulation and analysis\n",
        "import pandas as pd \n",
        "\n",
        "# Numpy is used for large, multi-dimensional arrays and matrices, along with mathematical operators on these arrays\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib is a data visualization library for 2D plots of arrays, built on NumPy arrays \n",
        "# and designed to work with the broader SciPy stack\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Seaborn is based on matplotlib, which aids in drawing attractive and informative statistical graphics.\n",
        "import seaborn as sns\n",
        "import tensorflow \n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fze-aokU0ukH"
      },
      "source": [
        "## 2. Setting Options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3FALggG0xXa"
      },
      "source": [
        "# suppress display of warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# display all dataframe columns\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# to set the limit to 3 decimals\n",
        "pd.options.display.float_format = '{:.7f}'.format\n",
        "\n",
        "# display all dataframe rows\n",
        "pd.options.display.max_rows = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT1P1WdK1vfZ"
      },
      "source": [
        "## 3. Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UOW6zwww7L1"
      },
      "source": [
        "### 3.1 Read the provided CSVs and check 5 random samples and shape to understand the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxT2g284xF1W"
      },
      "source": [
        "\n",
        "product_df = pd.read_csv('/content/drive/MyDrive/product_data.csv')\n",
        "product_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu8fNxW9m9Vr"
      },
      "source": [
        "product_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRjG44fRxGIq"
      },
      "source": [
        "import csv\n",
        "reviews_df = pd.read_csv('/content/drive/MyDrive/reviews.csv')#,error_bad_lines=False,quoting=csv.QUOTE_NONE )\n",
        "reviews_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJFM80wRh4zd"
      },
      "source": [
        "reviews_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sFQgdT6lEt6"
      },
      "source": [
        "product_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcMXG1kFlG5S"
      },
      "source": [
        "reviews_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rED6DbDBKTjM"
      },
      "source": [
        "## 4.  Data Analysis and EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awlqmp40xMfc"
      },
      "source": [
        "### 4.1 Drop unnecessary columns like 'url', 'image' from the product_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT4d-6TCxZCm"
      },
      "source": [
        "product_df = product_df.drop(['url','image','reviewUrl'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBXyOVmUla4X"
      },
      "source": [
        "product_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSmpE98bprVm"
      },
      "source": [
        "product_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk0WW5D5xZK9"
      },
      "source": [
        "### 4.2 Check statistical summary of both datasets. Note:- Include both numerical and object type columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylwcqQpcx_Tl"
      },
      "source": [
        "product_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s24zjhklrS2b"
      },
      "source": [
        "product_df.describe(include='O')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFaDkvIjyDtG"
      },
      "source": [
        "reviews_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkaL-sNrcpg"
      },
      "source": [
        "reviews_df.describe(include='object')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrkN4UAsoMU"
      },
      "source": [
        "reviews_df[reviews_df['helpfulVotes']==326]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSdGfadUyEdU"
      },
      "source": [
        "### 4.3 From the above statistical summary, write inferences like count of unique products, top brand, top title, range of rating, price range, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOwa4KmOp3ok"
      },
      "source": [
        "\n",
        "\n",
        "*   There are 720 unique products\n",
        "*   Rating ranges from 1 to 5. Mean rating is 3.71\n",
        "*   There are 10 brands of which samsung comes at top.\n",
        "*   Price ranges from 0 to 999.99 with 235 as mean price value\n",
        "*   There are no duplicate asin id\n",
        "*   To title is Apple iphone 6s\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMv_hXyxJKZK"
      },
      "source": [
        "### 4.4 Analyze the distribution of ratings and other categorical features like brand, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEhjSsMcyirD"
      },
      "source": [
        "sns.displot(data= product_df,x='rating')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVb2LLMZvGQq"
      },
      "source": [
        "sns.displot(data= product_df,x='rating',kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqUpy8CllTOj"
      },
      "source": [
        "sns.barplot(data=product_df,x=product_df.rating,y='brand')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2_qTVu_v8Rw"
      },
      "source": [
        "product_df['brand'].value_counts().plot(kind='pie',autopct='1.0f%%',figsize=(12,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l17rVvu9wPBi"
      },
      "source": [
        "product_df['brand'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXIr3rbRwf-4"
      },
      "source": [
        "sns.countplot(product_df.brand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwZBGODgyi1a"
      },
      "source": [
        "### 4.5 Display average rating per brand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4_aXAGiursG"
      },
      "source": [
        "product_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSBBiAv8yscd"
      },
      "source": [
        "# Calculating average rating per brand\n",
        "\n",
        "rating_per_brand = product_df.groupby(by='brand')['rating'].mean().sort_values(ascending=False)\n",
        "rating_per_brand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn3YbLAaw669"
      },
      "source": [
        "rating_per_brand.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUXuEwlgyvB0"
      },
      "source": [
        "### 4.6 Display average price per brand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACgIwVlyy3Pu"
      },
      "source": [
        "# Calculating average price per brand\n",
        "\n",
        "price_per_brand = product_df.groupby(by='brand')['price'].mean().sort_values(ascending=False)\n",
        "price_per_brand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz3nfhrQxG2j"
      },
      "source": [
        "price_per_brand.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0JfwL74y3a-"
      },
      "source": [
        "### 4.7 Display average 'totalReviews' per brand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfzciNxqzBYu"
      },
      "source": [
        "# Calculating average 'totalReviews' per brand\n",
        "price_per_brand = product_df.groupby(by='brand')['totalReviews'].mean().sort_values(ascending=False)\n",
        "price_per_brand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Y2w5tAxbDu"
      },
      "source": [
        "price_per_brand.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_fxI7OAeDUM"
      },
      "source": [
        "### 4.8 Merge two datasets using 'asin' and check the shape of the final dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svpHfWI9zNAP"
      },
      "source": [
        "df = pd.merge(reviews_df, product_df,how='left',left_on='asin',right_on='asin') \n",
        "df.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJkxAvFWyDD5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdTfwlL7fYpq"
      },
      "source": [
        "### 4.9 Rename important features with appropriate names.\n",
        "Imortant features - \"rating_x\": \"user_rating\", \"title_x\": \"review_title\", \"title_y\": \"item_title\", \"rating_y\": \"overall_rating\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEBTHfcb0C0F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI-6FCkZztXM"
      },
      "source": [
        "df.rename(columns={\"rating_x\": \"user_rating\", \"title_x\": \"review_title\",\"title_y\": \"item_title\",\"rating_y\":\"overall_rating\"},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz2Vj7qv0Ge1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNHEElHszthc"
      },
      "source": [
        "### 4.10 Select rows having verified reviews and check the shape of the final dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyav9_Zoz-rT"
      },
      "source": [
        "df = df[df.verified==True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FHlpN3x2R4m"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpKusPjdz-2q"
      },
      "source": [
        "### 4.11 Check the number of reviews for various brands and report the brand that have highest number of reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tux6vwr0JDb"
      },
      "source": [
        "# Calculating  the number of reviews for various brands \n",
        "reviews_brand = df.groupby(by='brand')['totalReviews'].count().sort_values(ascending=False)\n",
        "reviews_brand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHul99wY4JTY"
      },
      "source": [
        "reviews_brand.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPGjMFE-0Q5k"
      },
      "source": [
        "### 4.12 Drop irrelevant columns and keep important features like 'brand','body','price','user_rating','review_title' for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2WRpTZB3I9N"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfeM8keU3V9T"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_IvLN6e0e6z"
      },
      "source": [
        "df_final = df.drop(['asin', 'totalReviews','originalPrice', 'name', 'overall_rating', 'date', 'verified','item_title',  'helpfulVotes'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUm8fqvM4by_"
      },
      "source": [
        "df_final.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUFAvuSw6tFz"
      },
      "source": [
        "df_final.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzo_rVT60fDf"
      },
      "source": [
        "### 4.13 Perform univariate analysis. Check distribution of price, user_rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3vzILxZ0t0L"
      },
      "source": [
        "sns.displot(data=df_final,x='price')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVZOcwh_62rm"
      },
      "source": [
        "sns.displot(data=df_final,x='price',kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go3DsODz5Efc"
      },
      "source": [
        "sns.displot(data=df_final,x='user_rating')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvR0H6616-LG"
      },
      "source": [
        "sns.displot(data=df_final,x='user_rating',kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADwHzN5X7H7G"
      },
      "source": [
        "sns.countplot(df_final['user_rating'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdPJmGiy9mLW"
      },
      "source": [
        "df_final['user_rating'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Y_kE9T0uAf"
      },
      "source": [
        "### 4.14 Create a new column called \"sentiment\". It should have value as 1 (positive) if the user_Rating is greater than 3, value as 0 (negative) if the user_Rating <= 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktN_vHKW7Go9"
      },
      "source": [
        "df_final['sentiment'] = df_final['user_rating'].apply(lambda x : 1 if x > 3 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO9wrtVj5D1T"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4rxSZWp1VAb"
      },
      "source": [
        "### 4.15 Check frequency distribution of the 'sentiment'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt3gH7Iz1dVP"
      },
      "source": [
        "df_final['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-a605SY9ImY"
      },
      "source": [
        "sns.countplot(df_final['sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK0KMghP1ddb"
      },
      "source": [
        "### 4.16 Perform bivariate analysis. Check correlation/crosstab between features and write your inferences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scAV4fRg1nX0"
      },
      "source": [
        "df_final.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8ffX69s_DKT"
      },
      "source": [
        "\n",
        "\n",
        "*   user_rating and sentiments are positively correlated.\n",
        "*   price doesnt seem to have larger influence on either sentiments of user or their ratings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wrGbgSlDOox"
      },
      "source": [
        "sns.boxplot(x=df_final['sentiment'],y=df_final['price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRLbkEdmENsn"
      },
      "source": [
        "pd.crosstab(df_final['brand'],df_final['sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le_K1rFgDaYP"
      },
      "source": [
        "pd.crosstab(df_final['brand'],df_final['sentiment']).apply(lambda x : x/x.sum(),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nzj7ZXVLakx"
      },
      "source": [
        "## 5. Text Preprocessing and Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbC_RPndnlf3"
      },
      "source": [
        "We will analyze the 'body' and 'review_title' to gain more understanding.\n",
        "\n",
        "We will peform the below tasks\n",
        "\n",
        "- Convert the text into lowercase\n",
        "- Remove punctuation\n",
        "- Remove stopwords (English, from nltk corpus)\n",
        "- Remove other keywords like \"phone\" and brand name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnhMQsxz2DJH"
      },
      "source": [
        "### 5.1 Change the datatype of the 'body' column to 'str' and convert it into lowercase. Print any two samples and check the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Zwnfsl_3mk"
      },
      "source": [
        "df_final.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foyOehmpA-mz"
      },
      "source": [
        "df_final['body'] = df_final['body'].astype('string')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHOlPmRaBJad"
      },
      "source": [
        "df_final.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0daMw4QPFXN6"
      },
      "source": [
        "df_final.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eREnBHFHBjll"
      },
      "source": [
        "df_final['keywords'] = df_final['body'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kT62frOI_zJ"
      },
      "source": [
        "df_final['keywords'].head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnX3xhYxJRB8"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsppV0X52VXf"
      },
      "source": [
        "### 5.2 Remove punctuations from the lowercased 'body' column and display at least two samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQXKc8et2onG"
      },
      "source": [
        "import string\n",
        "df_final['keywords'] = df_final['keywords'].str.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oatG55BbMofO"
      },
      "source": [
        "df_final.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3uyWByIOH-V"
      },
      "source": [
        "#Using regEx\n",
        "\n",
        "df_final['keywords'] = df_final['keywords'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe7EOXQFPgil"
      },
      "source": [
        "df_final.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zk7ja6A2owN"
      },
      "source": [
        "### 5.3 Remove stop words from the above pre-processed 'body' column and display at least two samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DbTf2yc2VOQ"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bNAFID9Rou3"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA4CpYp1Tk7j"
      },
      "source": [
        "df_final['keywords'] = df_final['keywords'].astype('str')\n",
        "df_final['keywords'] = df_final['keywords'].apply(lambda words: ' '.join(w for w in words.split() if w not in stop_words))\n",
        "df_final.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQNvXay42yaQ"
      },
      "source": [
        "### 5.4 Apply lemmatisation on the above preprocessed text and display a few samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ1VfFaa3DET"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aRKfr3-YwHA"
      },
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFX2z7noZL8z"
      },
      "source": [
        "def lemmetize_text(text):\n",
        "  return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-nJ-rIFZw6n"
      },
      "source": [
        "df_final['lemm'] = df_final['keywords'].apply(lemmetize_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xboadoHYcXXB"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKB8-qdKcp4a"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "  \n",
        "print(\"replacement :\", lemmatizer.lemmatize(\"replacement\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "  \n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzweL_fA3DiN"
      },
      "source": [
        "### 5.5 Check most common and rare words in the processed text\n",
        "- We can also write a function to check word frequency of the text (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIAyX3N6lz5"
      },
      "source": [
        "from collections import Counter\n",
        "cnt = Counter()\n",
        "for text in df_final[\"keywords\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1\n",
        "        \n",
        "cnt.most_common(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7I0V2fZiNsK"
      },
      "source": [
        "rare_words = 10\n",
        "\n",
        "cnt.most_common()[:-rare_words-1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkgi2czjlEuU"
      },
      "source": [
        "#positive sentiments\n",
        "df_pos = df_final[df_final[\"sentiment\"]==1]\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "cnt = Counter()\n",
        "for text in df_pos[\"keywords\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1\n",
        "        \n",
        "cnt.most_common(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UbdTGsv60t1"
      },
      "source": [
        "### 5.6 Initialize tf-idf vectorizer and transform the preprocessed body text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jfo6go_69yh"
      },
      "source": [
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CucM9CSDd32S"
      },
      "source": [
        "# Initialize TF-IDF vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer1 = TfidfVectorizer(ngram_range=(2,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56A3Ws6FeGeq"
      },
      "source": [
        "df_final['tfidf'] = tfidf_vectorizer.fit_transform(df_final[\"keywords\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa0rSQQFhalN"
      },
      "source": [
        "df_final['tfidf1'] = tfidf_vectorizer.fit_transform(df_final[\"keywords\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7GHB0yZeZRF"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtFevhIbegWj"
      },
      "source": [
        "tfidf = tfidf_vectorizer.fit_transform(df_final[\"keywords\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTt049X-gekc"
      },
      "source": [
        "tfidf1 = tfidf_vectorizer1.fit_transform(df_final['keywords'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBttygtlepA_"
      },
      "source": [
        "tfidf.get_shape()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5VPAypXgqh3"
      },
      "source": [
        "tfidf1.get_shape()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dqPXETLKN0h"
      },
      "source": [
        "### 5.7 Segregate the data into dependent (sentiment) and independent (transformed body using tf-idf) features for building a classifier. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpOLAYn07W6F"
      },
      "source": [
        "y = df_final['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K03FO0q7XBP"
      },
      "source": [
        "### 5.9 Split the data into Train & Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D548-7cE7dZa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y1_train, y1_test = train_test_split(tfidf, y, random_state = 50, stratify=y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhD1a-beKvE7"
      },
      "source": [
        "## 6. Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPFovmN03exD"
      },
      "source": [
        "### 6.1 Build a random forest classifier to predict the 'sentiment'\n",
        "### 6.2 Predict on test set\n",
        "### 6.3 Check accuracy and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ytdD-_30P9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf1 = RandomForestClassifier()\n",
        "rf_clf1.fit(X_train, y1_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMK8rXrBnZq5"
      },
      "source": [
        "print(\"Train accuracy of the model is : \",rf_clf1.score(X_train, y1_train))\n",
        "print(\"Test accuracy of the model is : \",rf_clf1.score(X_test, y1_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNET67Jihrak"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y1_pred = rf_clf1.predict(X_train)\n",
        "confusion_matrix(y1_train, y1_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd7n_Ajwhrpu"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y1_pred = rf_clf1.predict(X_test)\n",
        "confusion_matrix(y1_test, y1_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ6Ke4hl30Zk"
      },
      "source": [
        "X_train, X_test, y1_train, y1_test = train_test_split(tfidf1, y, random_state = 50, stratify=y, test_size=0.3)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf1 = RandomForestClassifier()\n",
        "rf_clf1.fit(X_train, y1_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmSffAPWnePg"
      },
      "source": [
        "print(\"Train accuracy of the model is : \",rf_clf1.score(X_train, y1_train))\n",
        "print(\"Test accuracy of the model is : \",rf_clf1.score(X_test, y1_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D28OgUGh6fS"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y1_pred = rf_clf1.predict(X_train)\n",
        "confusion_matrix(y1_train, y1_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwAySEWOh6jU"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y1_pred = rf_clf1.predict(X_test)\n",
        "confusion_matrix(y1_test, y1_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey7an7ukLxWB"
      },
      "source": [
        "## 7. Write your conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pk8hvcEl6uh"
      },
      "source": [
        "\n",
        "\n",
        "*   We can see model is overfit , so we can tune some hyperparameters to improve the accuracy. \n",
        "*   We can also tune some hyperparameters to reduce the shape of our tfidf,etc\n",
        "*   We can try max feature \n",
        "*   We are only usinf body attribute for analysis in this notebook we can add review_title and also brand along with body to get some deeper insights.  \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}